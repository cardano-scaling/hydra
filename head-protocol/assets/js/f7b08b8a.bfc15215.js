"use strict";(self.webpackChunkhydra_head_protocol_docs=self.webpackChunkhydra_head_protocol_docs||[]).push([[4259],{34265:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"1","metadata":{"permalink":"/head-protocol/adr/1","source":"@site/adr/2021-06-05_001-record-architectural-decisions.md","title":"1. Record Architecture Decisions\\n","description":"Status","date":"2021-06-05T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":0.515,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"1","title":"1. Record Architecture Decisions\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"nextItem":{"title":"2. Reactive Core\\n","permalink":"/head-protocol/adr/2"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nWe are in search for a means to describe our technical architecture.\\n\\nWe are a small team working in a very lean and agile way (XP), so we naturally prefer also light-weight documentation methods which also accommodate change easily.\\n\\n## Decision\\n\\n* We will use _Architecture Decision Records_, as described by Michael Nygard in this [article](http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions).\\n* We will follow the convention of storing those ADRs as Markdown formatted documents stored under `docs/adr` directory, as exemplified in Nat Pryce\'s [adr-tools](https://github.com/npryce/adr-tools). This does not imply we will be using `adr-tools` itself.\\n\\n## Consequences\\n\\nSee Michael Nygard\'s article, linked above."},{"id":"2","metadata":{"permalink":"/head-protocol/adr/2","source":"@site/adr/2021-06-06_002-reactive-core.md","title":"2. Reactive Core\\n","description":"Status","date":"2021-06-06T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":0.975,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"2","title":"2. Reactive Core\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"1. Record Architecture Decisions\\n","permalink":"/head-protocol/adr/1"},"nextItem":{"title":"3. Asynchronous Duplex Client API","permalink":"/head-protocol/adr/3"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nWe are looking for a way of expressing the Hydra Head protocol logic in a Hydra node.\\n\\nThe Hydra Head protocol is defined as a _State machine_ in the paper, whose transitions are inputs that come from different sources which can emit outputs to other instances of the state machine or the mainchain. See the [FC2021](https://iohk.io/en/research/library/papers/hydrafast-isomorphic-state-channels/) paper for details.\\n\\nIt should also be easy to review / give feedback to researchers.\\n\\nWe are familiar with React\'s [redux](https://react-redux.js.org/) way of structuring applications, which is inspired by [The Elm Architecture](https://guide.elm-lang.org/architecture/), which itself is a simplification of [Functional Reactive Programming](https://en.wikipedia.org/wiki/Functional_reactive_programming) principles.\\n\\nWe have experienced benefits with _Event Sourcing_ in the domain of persistence in the past.\\n\\n## Decision\\n\\nImplements the Hydra Head core logic as a _loop_ that:\\n1. Consumes _input events_ from an event _queue_\\n2. Applies each _event_ to the current _state_ yielding potentially an _updated state_ and a sequence of _effects_\\n3. Execute all _effects_.\\n\\n## Consequences\\n\\nThe internal state is only ever changed through _Events_.\\n\\nThe core state machine _transition_ function _is pure_ and reviewing it requires minimal Haskell knowledge.\\n\\nSide effects are all handled at the `node` level."},{"id":"3","metadata":{"permalink":"/head-protocol/adr/3","source":"@site/adr/2021-06-07_003-asynchronous-duplex-api.md","title":"3. Asynchronous Duplex Client API","description":"Status","date":"2021-06-07T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":0.845,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"3","title":"3. Asynchronous Duplex Client API","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"2. Reactive Core\\n","permalink":"/head-protocol/adr/2"},"nextItem":{"title":"4. Use Handle to model Effects\\n","permalink":"/head-protocol/adr/4"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nThe [_reactive_ nature of the Hydra node](/adr/2) means that\\nclients produce a _stream_ of _inputs_ to a node which in turns issues a stream\\nof _outputs_ representing the outcome of previous inputs or resulting from\\ninteraction with peers in the network.\\n\\nFor example, a client may send a _command_ as _input_, upon which the node might\\ndo something. When that something is finished, a _output_ does indicate that.\\nHowever, there might also be an _output_ emitted to the client when another peer\\ninteracted with \\"our\\" node.\\n\\nQueries, messages by clients which do only fetch information from the node, are\\nnot in scope of this ADR.\\n\\n## Decision\\n\\n* We use a single, full-duplex communication channel per client connected to a Hydra node\\n* This is implemented using a simple [Websocket](https://datatracker.ietf.org/doc/html/rfc6455) with messages corresponding to `Input`s and `Output`s.\\n\\n## Consequences\\n\\n* Clients needing a synchronous API need to implement it on top\\n* Clients can receive _outputs_ decorrelated from any _inputs_ and at any time"},{"id":"4","metadata":{"permalink":"/head-protocol/adr/4","source":"@site/adr/2021-06-08_004-use-handle-to-model-effects.md","title":"4. Use Handle to model Effects\\n","description":"Status","date":"2021-06-08T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.355,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"4","title":"4. Use Handle to model Effects\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"3. Asynchronous Duplex Client API","permalink":"/head-protocol/adr/3"},"nextItem":{"title":"5. Use io-classes\\n","permalink":"/head-protocol/adr/5"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nGiven we are structuring Hydra node as a [reactive core](/adr/2) we need a way to ensure a strict separation of pure and impure (or effectful) code.\\n\\nWe want to be able to test those impure/effectful parts of the code. This requires a means for exchanging the actual implementation for e.g. the function to send messages over a network.\\n\\nAlso we want the ability to swap implementations not only for testing, but also be able\\nto accommodate different usage scenarios, e.g. use a different middleware\\ndepending on peer configuration.\\n\\nIn Haskell there are various common _patterns_ to model effects:\\n  * [Tagless final encoding](http://okmij.org/ftp/tagless-final/index.html) also known as _MTL-style_ although using typeclasses to implement is [not necessary](https://www.foxhound.systems/blog/final-tagless/), whereby Effect(s) are expressed as typeclass(es) which are propagated as constraints\\n  * [Free monads](https://reasonablypolymorphic.com/blog/freer-monads/), or any variant thereof like Eff, freer, extensible-effects, whereby effect(s) are expressed as ADTs which are _interpreted_ in the context of an _Effect stack_\\n  * [Handle](https://jaspervdj.be/posts/2018-03-08-handle-pattern.html) pattern also known as _record-of-functions_ whereby effects are grouped together in a datatype with a single record constructor\\n\\n(These tradeoffs also appear in other functional languages like\\n[F#](https://medium.com/@dogwith1eye/prefer-records-of-functions-to-interfaces-d6413af4d2c3))\\n\\nThere is not one most favored solution though and we all have various\\nexperiences with these techniques.\\n\\n## Decision\\n\\nEffectful components of the Hydra node (our code) will be defined using the _Handle pattern_.\\n\\nThere might be other techniques in use because of libraries used etc.\\n\\n## Consequences\\n\\nFor example, the network component is defined as:\\n  ```hs\\n  newtype Network m = Network\\n    { broadcast :: MonadThrow m => HydraMessage -> m ()\\n    }\\n  ```\\nThere might be multiple `createNetwork :: m (Network m)` functions"},{"id":"5","metadata":{"permalink":"/head-protocol/adr/5","source":"@site/adr/2021-06-09_005-use-io-sim-classes.md","title":"5. Use io-classes\\n","description":"Status","date":"2021-06-09T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.055,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"5","title":"5. Use io-classes\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"4. Use Handle to model Effects\\n","permalink":"/head-protocol/adr/4"},"nextItem":{"title":"6. Network broadcasts all messages\\n","permalink":"/head-protocol/adr/6"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nAlthough we try to contain the use of IO at the outskirt of the Hydra node using [Handle pattern](/adr/4) and [Reactive core](/adr/2), low-level effects are still needed in various places, notably to define concurrently executing actions, and thus need to be tested\\n\\nTesting asynchronous and concurrent code is notoriously painful\\n\\nThe ouroboros consensus test suite and [hydra-sim](https://github.com/cardano-scaling/hydra-sim) simulation have demonstrated the effectiveness of abstracting concurrent primitives through the use of typeclasses (MTL-style pattern) and being able to run these as pure code, harvesting and analysing produced execution traces.\\n\\nThere are other such libraries, e.g. [concurrency](https://hackage.haskell.org/package/concurrency) and [dejafu](https://hackage.haskell.org/package/dejafu), as well as the venerable [exceptions](https://hackage.haskell.org/package/exceptions) (for abstracting exception throwing).\\n\\n## Decision\\n\\nFor all IO effects covered by the library, use functions from typeclasses exposed by [io-classes](https://github.com/input-output-hk/ouroboros-network/tree/e338f2cf8e1078fbda9555dd2b169c6737ef6774/io-classes). As of this writing, this covers:\\n  * All STM operations through `MonadSTM`\\n  * Time and timers through `MonadTime` and `MonadTimer`\\n  * Concurrency through `MonadAsync`, `MonadFork`\\n  * Exceptions through `MonadThrow`, `MonadCatch` and `MonadMask`\\n\\n## Consequences\\n\\nWe can use `io-sim` to evaluate IO-ish functions easily\\n\\nInstantiation to concrete IO is pushed at the outermost layer, eg. in the `Main` or tests.\\n\\nAs some of these functions and typeclasses clash with the\\n[cardano-prelude](https://github.com/input-output-hk/cardano-prelude) we might\\nwant to define a custom prelude (candidate for another ADR)"},{"id":"6","metadata":{"permalink":"/head-protocol/adr/6","source":"@site/adr/2021-06-10_006-network-broadcasts-all-messages.md","title":"6. Network broadcasts all messages\\n","description":"Status","date":"2021-06-10T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":0.925,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"6","title":"6. Network broadcasts all messages\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"5. Use io-classes\\n","permalink":"/head-protocol/adr/5"},"nextItem":{"title":"7. Use with-pattern based component interfaces\\n","permalink":"/head-protocol/adr/7"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nThe simplified Head protocol in the [Hydra\\npaper](https://iohk.io/en/research/library/papers/hydrafast-isomorphic-state-channels/)\\nrequires _unicast_ and _multicast_ messaging between participants. However, this\\ncan be simplified to only _multicast_ by also sending `AckTx` messages to all\\nparticipants and removing the necessity for `ConfTx`.\\n\\nThere is already a battle-tested implementation for _broadcasting_ messages over\\nnetworks with any kind of topology (mesh), namely the\\n[TxSubmission](https://github.com/input-output-hk/ouroboros-network/tree/master/ouroboros-network/src/Ouroboros/Network/TxSubmission)\\nprotocol of `ouroroboros-network`.\\n\\nIf the network connects only to interested peers, _broadcast_ is essentially the\\n_multicast_ required by the protocol. If this is not the case, some addressing\\nscheme is required, and _broadcast_ would be a waste of resources.\\n\\n## Decision\\n\\n* All messages emitted by a Hydra node through the network component are _broadcasted_ to _all_ nodes in the network\\n* This implies the emitter shall itself receive the message.\\n\\n## Consequences\\n\\n* The network layer is responsible for ensuring that sent messages effectively\\n  reach all nodes in the network. How this is achieved is left as an\\n  implementation detail, ie, whether or not it uses relaying.\\n* We need to make sure all Head participants are connected to the same network."},{"id":"7","metadata":{"permalink":"/head-protocol/adr/7","source":"@site/adr/2021-06-11_007-with-pattern-component-interfaces.md","title":"7. Use with-pattern based component interfaces\\n","description":"Status","date":"2021-06-11T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.17,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"7","title":"7. Use with-pattern based component interfaces\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"6. Network broadcasts all messages\\n","permalink":"/head-protocol/adr/6"},"nextItem":{"title":"8. Custom Prelude\\n","permalink":"/head-protocol/adr/8"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nThe _with pattern_ or _bracket pattern_ is a functional programming idiom, a\\nparticular instance of _Continuation-Passing Style_, whereby one component that\\ncontrols some resource that is consumed by another component of the system, is\\ncreated via a function that takes as argument a function consuming the resource,\\ninstead of returning it. This pattern allows safe reclaiming of resources when\\nthe \\"wrapped\\" action terminates, whether normally or unexpectedly.\\n\\nTODO \\"Tying the knot\\"\\n\\n## Decision\\n\\nWe use this pattern to provide interfaces to all _active components_, which\\nexchange messages with other components of the system. A prototypical signature\\nof such a component could be:\\n\\n  ```hs\\n  type Component m = inmsg -> m ()\\n  type Callback m = outmsg -> m ()\\n\\n  withXXX :: Callback m -> (Component m -> m a) -> m a\\n  ```\\n\\nNote that `withXXX` can also allocate resources in order to provide `Component`\\nor use the `Callback`, e.g. fork threads which invoke `Callback`, but also make\\nsure they are cleaned up.\\n\\n## Consequences\\n\\nComponents can be layered on top of another to provide additional behavior given the same interface. This also similar to \\"decorating\\" in the object-orientation world.\\n\\nIf the `Component` is agnostic about the messages it consumes/produces, it can be defined as a [`Contravariant` functor](https://hackage.haskell.org/package/base-4.15.0.0/docs/Data-Functor-Contravariant.html) and the `Callback` part as a (covariant) `Functor`. This makes it possible to use `map` and `contramap` operations to transform messages."},{"id":"8","metadata":{"permalink":"/head-protocol/adr/8","source":"@site/adr/2021-06-18_008-use-custom-prelude.md","title":"8. Custom Prelude\\n","description":"Status","date":"2021-06-18T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.68,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"8","title":"8. Custom Prelude\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"7. Use with-pattern based component interfaces\\n","permalink":"/head-protocol/adr/7"},"nextItem":{"title":"9. Simplify Logging\\n","permalink":"/head-protocol/adr/9"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nIn a Haskell project, we often get to use and re-use the same libraries and functions. Haskell comes with a default `Prelude` package with the `base` library, which provides a good and sensible starting point. However, the base `Prelude` also comes with a few quirks:\\n\\n- Many commonly used functions or constructors are not exported by default (e.g. `bracket`, `foldM`, `first`, `lift`, `forM`, `when`, `SomeException`, `Set`, `&` ...etc).\\n- Many functions in the base Prelude are partial, like `head` or `read`. \\n- Many functions simply happens in plain `IO`, whereas applications usually try to push IO to the boundary as much as possible (for example, using mtl-style class constraints).\\n- The interface for I/O operations in the base Prelude is `String`, which comes with quite major performance hit and often forces to convert back and forth to `Text` or `ByteString` equivalents.\\n\\nAll-in-all, while it _does the job_, the base `Prelude` may not necessarily be the most _convenient_ prelude for an active project development. \\n\\n## Decision\\n\\nWe\'ll use a custom prelude to help us get more productive and more importantly, to reduce the daily friction of our interactions with the base prelude. While [`relude`](https://hackage.haskell.org/package/relude) makes for a good candidate, we still chose to re-wrap it in a custom `Hydra.Prelude` module to grant us the ability to add or remove a few things specifics to Hydra and Cardano in general. In particular, we will hide from `relude` all the re-exports of the [`stm`](https://hackage.haskell.org/package/stm) library in favor of [`io-classes`](https://github.com/input-output-hk/ouroboros-network/tree/e338f2cf8e1078fbda9555dd2b169c6737ef6774/io-classes) which we already use pervasively and which provides (among other things) most of the same capabilities.\\n\\n## Consequences\\n\\n- Remove uses of \'cardano-prelude\' in favor of a new \'hydra-prelude\' module.\\n- Cleaning up of imports from existing file modules.\\n- Happier feeling day after day from using a developer-friendly prelude.\\n- Stop loosing time in often re-importing the same functions over and over. \\n- Have an explicit point for discouraging / blessing usage of one or the other function, as well as documenting such decisions"},{"id":"9","metadata":{"permalink":"/head-protocol/adr/9","source":"@site/adr/2021-08-19_009-simplify-logging.md","title":"9. Simplify Logging\\n","description":"Status","date":"2021-08-19T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"9","title":"9. Simplify Logging\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"8. Custom Prelude\\n","permalink":"/head-protocol/adr/8"},"nextItem":{"title":"10. Use direct connection to `cardano-node`\\n","permalink":"/head-protocol/adr/10"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* Logs are critical to provide _observability_ to Hydra nodes\' operators\\n* Providing the needed components and tools to be able to configure logging and monitoring to each operator\'s liking should not be the responibility of the Hydra node, and requires complex machinery that will need to be maintained and evolved\\n* When a problem occurs in production, if the process is not verbose enough it can be very hard to analyse the problem\\n  * Enabling dynamic changes of verbosity in logs is both complex to implement and comes too late\\n  * Deciding in the code on what\'s the right \\"severity\\" for a log entry leads to dropping important information on _how_ some error occurred\\n\\n## Decision\\n\\n_Therefore_\\n\\nHydra node provides a very simplified logging mechanism whereby:\\n* All logs are emitted as JSON-encoded structures providing some metadata (timestamp, threadId) around well-defined data\\n* Each _log entry_ is written to the `hydra-node` process\' _stdout_ port, one line per entry\\n\\n**Note**: Proper redaction of sensitive information contained in log entries should still be handled in the code.\\n\\n## Consequences\\n\\n* It is the responsibility of the node operator to filter severity or otherwise post-process the logs"},{"id":"10","metadata":{"permalink":"/head-protocol/adr/10","source":"@site/adr/2021-10-23_010-use-direct-chain.md","title":"10. Use direct connection to `cardano-node`\\n","description":"Status","date":"2021-10-23T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"10","title":"10. Use direct connection to `cardano-node`\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"9. Simplify Logging\\n","permalink":"/head-protocol/adr/9"},"nextItem":{"title":"11. Use cardano-api\\n","permalink":"/head-protocol/adr/11"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* On-chain validation is a critical part of the Hydra protocol. It requires both the ability to _submit_ transactions to the _layer 1_ chain, advancing the state of a head, and _observing_ those transactions as the [Plutus](https://github.com/input-output-hk/plutus) contracts are validated.\\n* The [Plutus Application Framework](https://github.com/input-output-hk/plutus-apps) is expected to provide the necessary machinery to allow \'smart contract\' applications to interact with the chain, but it\'s still under active development and not ready for deployment on-chain.\\n* We want to gather feedback as early as possible and deliver a fully functional Hydra Head node for early adopters to test on a \'real\' chain (testnet).\\n* Our experiment connecting directly to a Cardano node has been conclusive. We can:\\n  * Connect to a node using local protocols\\n  * Build and submit Head transactions triggering smart contracts validation\\n  * Observe transactions using chain-sync protocol.\\n\\n## Decision\\n\\n_Therefore_\\n\\nFor the time being, until _Plutus Application Framework_ is released, we will implement on-chain interaction of Hydra nodes _directly_, connecting to a Cardano node through a _local socket_.\\n\\n## Consequences\\n\\n* Limit Hydra dependencies to the [Plutus](https://github.com/input-output-hk/plutus) repository\\n* Remove all PAB-related code as well as off-chain `contract`s code and related dependencies."},{"id":"11","metadata":{"permalink":"/head-protocol/adr/11","source":"@site/adr/2021-11-18_011-use-cardano-api.md","title":"11. Use cardano-api\\n","description":"Status","date":"2021-11-18T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.095,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"11","title":"11. Use cardano-api\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"10. Use direct connection to `cardano-node`\\n","permalink":"/head-protocol/adr/10"},"nextItem":{"title":"12. Top-down Test-driven Design\\n","permalink":"/head-protocol/adr/12"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* To implement Hydra Head\'s ledger we have been working with the [ledger-specs](https://github.com/input-output-hk/cardano-ledger-specs) packages which provide a low-level interface to work with transactions and ledgers\\n  * We also use a lightly wrapped ledger-specs API as our interface for Off-chain transaction submission. This introduced some boilerplate in order to align with cardano-api and provide JSON serialisation.\\n* In our initial experiments [connecting directly](/adr/10) to a cardano node we have also been using the ledger API for building transactions for want of some scripts-related features in the cardano-api\\n* cardano-api is expected to be the supported entrypoint for clients to interact with Cardano chain while ledger-specs is reserved for internal use and direct interactions with ledgers\\n* cardano-api now provides all the features we need to run our on-chain validators\\n\\n## Decision\\n\\n_Therefore_\\n\\n* Use cardano-api types and functions instead of ledger-specs in `Hydra.Chain.Direct` component\\n* Use cardano-api types instead of custom ones in `Hydra.Ledger.Cardano` component\\n\\n## Consequences\\n\\n* Removes the boilerplate in `Hydra.Ledger.Cardano` required to map cardano-api types sent by clients to builtin and ledger-specs types\\n* Simplifies the  `Hydra.Chain.Direct` component:\\n  * Replaces custom transaction building in `Tx`\\n  * Replaces custom transaction fees calculation and balancing in `Wallet`\\n  * Replace low-level connection establishment using cardano-api functions connecting to the node (keeping the chain sync subscription)"},{"id":"12","metadata":{"permalink":"/head-protocol/adr/12","source":"@site/adr/2021-11-25_012-top-down-test-driven-design.md","title":"12. Top-down Test-driven Design\\n","description":"Status","date":"2021-11-25T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.47,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"12","title":"12. Top-down Test-driven Design\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"11. Use cardano-api\\n","permalink":"/head-protocol/adr/11"},"nextItem":{"title":"13. Plutus Contracts Testing Strategy\\n","permalink":"/head-protocol/adr/13"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* [Test-Driven Development](https://en.wikipedia.org/wiki/Test-driven_development) or _Test-Driven Design_ is a technique that helps team promotes simple and loosely coupled design, reduces the amount of code written, increases confidence in delivered software by providing a high level of code coverage by regression tests, and improves development speed through shorter feedback loop\\n* While initially focused on _unit tests_, TDD has evolved over time to include higher-level tests like [Behaviour Driven Development](https://en.wikipedia.org/wiki/Behavior-driven_development) or [Specification by Example](https://en.wikipedia.org/wiki/Specification_by_example), leading to comprehensive strategies like the [Outside-In Diamond TDD](http://tpierrain.blogspot.com/2021/03/outside-in-diamond-tdd-1-style-made.html)\\n* Being a foundational part of scalable applications based on Cardano blockchain, Hydra Head needs to be released early, often, and with high assurance in order to benefit from early adopters\' feedback\\n\\n## Decision\\n\\n_Therefore_\\n\\nWe start as early as possible with _End-to-End_ tests, gradually making them more complex as we develop the various components but starting with something simple (like a system-level but dummy chain and hydra network).\\n\\nWe flesh out other integration tests as needed, when we refine the technological stack used for the various bits and pieces.\\n\\nWe do most of our work in the _Executable Specifications_ layer while we are developing the core domain functions, eg. the Head protocol. The rationale being this is the level at which we can test the most complex behaviours in the fastest and safest possible way as we everything runs without external dependencies or can even run as pure code using io-sim.\\n\\nWe tactically drop to _Unit tests_ level when dealing with the protocol\'s \\"fine prints\\".\\n\\n## Consequences\\n\\n* Development of each \\"feature\\", whether new or change to existing one, should start with a test defined at the highest level possible, but no higher\\n* A detailed presentation of the various testing layers is available in the [wiki](https://github.com/cardano-scaling/hydra/wiki/Testing-Strategy)"},{"id":"13","metadata":{"permalink":"/head-protocol/adr/13","source":"@site/adr/2022-01-19_013-contract-testing-strategy.md","title":"13. Plutus Contracts Testing Strategy\\n","description":"Status","date":"2022-01-19T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.26,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"13","title":"13. Plutus Contracts Testing Strategy\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"12. Top-down Test-driven Design\\n","permalink":"/head-protocol/adr/12"},"nextItem":{"title":"14. Token usage in Hydra Scripts\\n","permalink":"/head-protocol/adr/14"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* We are implementing our custom ([Direct](/adr/10)) interaction w/ Cardano blockchain and not using the PAB nor the `Contract` monad to define off-chain contract code\\n* This implies we cannot use the [official](https://github.com/input-output-hk/plutus-apps/blob/main/plutus-contract/src/Plutus/Contract/Test.hs) testing framework for Contracts which relies on `Contract` monad and emulator traces nor the [QuickCheck based framework](https://plutus-apps.readthedocs.io/en/latest/plutus/tutorials/contract-testing.html)\\n* We want to follow our [Test-Driven Development](/adr/12) approach for contracts as this is a critical part of Hydra\\n* On-Chain Validators need not only to be correct and functional, but also secure and hardened against malicious parties\\n\\n## Decision\\n\\n_Therefore_\\n\\n* We test-drive single contracts code using _Mutation-Based Property Testing_\\n* Contracts are tested through the construction of actual _transactions_ and running phase-2 ledger validation process\\n* We start from a \\"healthy\\" transaction, that\'s expected to be correct and stay so\\n* Contract code is initially `const True` function that validates any transaction\\n* We flesh the contract\'s code piecemeal through the introduction of _Mutations_ that turn a healthy transaction into an expectedly invalid one\\n* We gradually build a set of combinators and generators that make it easier to mutate arbitrarily transactions, and combine those mutations\\n\\n## Consequences\\n\\n* We make the contracts\' _Threat model_  explicit through the tests we write, which should help future auditors\' work\\n* We\'ll need an additional layer of tests to exercise the Hydra OCV State Machine through _sequence of transactions_. This could be implemented using [quickcheck-dynamic](https://github.com/input-output-hk/plutus-apps/tree/main/quickcheck-dynamic) library, or other tools that are currently being developed by the Cardano community"},{"id":"14","metadata":{"permalink":"/head-protocol/adr/14","source":"@site/adr/2022-02-14_014-hydra-script-tokens.md","title":"14. Token usage in Hydra Scripts\\n","description":"Status","date":"2022-02-14T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":2.5,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"14","title":"14. Token usage in Hydra Scripts\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"13. Plutus Contracts Testing Strategy\\n","permalink":"/head-protocol/adr/13"},"nextItem":{"title":"15. Configuration Through an Admin API\\n","permalink":"/head-protocol/adr/15"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* The Hydra on-chain-verification scripts are used to validate Hydra protocol transactions and ensure they are lawful.\\n* At least these three properties need to be enforced:\\n    - Authentication: ensure that only Head participants can, for example, `abort` a Head\\n    - Contract continuity: ensure that a Head was `init`ialized before it can be opened by a `collectCom` tx.\\n    - Completeness: ensure that all Head participants had chance to `commit` funds to a Head.\\n* The Hydra Head paper introduces **participation tokens (PT)** and a **state thread token (ST)** for that matter.\\n* Such tokens (a.k.a native assets) are identified by the `CurrencySymbol`, that is the hash of their `MintingPolicyScript` (a.k.a `PolicyID` in the ledger), and a `ByteString`, the socalled `TokenName` (a.k.a as `AssetName` in the ledger, see [shelley-ma ledger spec](https://hydra.iohk.io/job/Cardano/cardano-ledger-specs/specs.shelley-ma/latest/download-by-type/doc-pdf/shelley-ma#subsection.3.2))\\n* There can be multiple Hydra Heads on a network and a `hydra-node` need to distinguish individual Head instances or even (later) keep track of multiple Heads. Concretely, this means that we need to infer a Head identifier (`HeadId`) from observing each of the Hydra protocol transactions. \\n\\n## Decision\\n\\n* We solve both challenges by defining that ST and PTs **shall use the same** `MintingPolicyScript` and thus have same `CurrencySymbol`\\n* The `MintingPolicyScript` shall be parameterized by `TxOutRef` to yield a unique `CurrencySymbol` per Head\\n(similar to the [`OneShotCurrency`](https://github.com/input-output-hk/plutus/tree/1efbb276ef1a10ca6961d0fd32e6141e9798bd11/plutus-use-cases/src/Plutus/Contracts/Currency.hs) example)\\n* ST and one PT per participant are minted in the `initTx`\\n* The `TokenName` of the ST can be any well-known `ByteString`, e.g. `\\"HydraHeadV1\\"`\\n* The `TokenName` of the PTs needs to be the `PubKeyHash` of the respective participant\\n\\n## Consequences\\n\\n* Heads can be identified by looking for the `ST` in `init`, `collectCom`, `close`, `contest` or `fanout` transactions, or the `PT` in `commit` transactions. In both cases, the `CurrencySymbol == HeadId`\\n* Our scripts become simpler as we only need to check that ST/PT are paid forward, instead of needing to check datums\\n* The datum produced by `commit` txs (and consumed by `collectCom`) is `Just SerializedTxOut`, which is simpler than also keeping the participant which committed in the datum (compare to full life-cycle of [0.3.0](https://github.com/cardano-scaling/hydra/tree/0.3.0/docs/images/on-chain-full.jpg)).\\n\\n* The `v_head` script validator does not need to be parameterized, which makes discovering new Heads (and also tracking them for metrics) easier as the address to watch for is common to all Heads (of the same `v_head` version).\\n* The `v_head` script (path) for the abort life-cycle can be implemented already much safer by checking that all PTs are burned on the `abort` transaction (counting inputs in abort life-cycle of [0.3.0](https://github.com/cardano-scaling/hydra/tree/0.3.0/docs/images/on-chain-abort.jpg)).\\n* Updated diagrams for the [full](img/on-chain-full.jpg) and [abort](img/on-chain-abort.jpg) on-chain life-cycles of a Hydra Head.\\n\\n## Follow-up questions\\n\\n* What value does the `ST` actually add? We could always look for the `PT` to identify a Head and contract continuity would already be achieved by the `PT`s!\\n* In discussions it turned out to be not clear where the Head\'s `CurrencySymbol` is coming from, and consequently how to identify that an `ST` is indeed an `ST`?"},{"id":"15","metadata":{"permalink":"/head-protocol/adr/15","source":"@site/adr/2022-03-17_015-admin-api.md","title":"15. Configuration Through an Admin API\\n","description":"Status","date":"2022-03-17T00:00:00.000Z","tags":[{"inline":true,"label":"Proposed","permalink":"/head-protocol/adr/tags/proposed"}],"readingTime":3.105,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"15","title":"15. Configuration Through an Admin API\\n","authors":[],"tags":["Proposed"]},"unlisted":false,"prevItem":{"title":"14. Token usage in Hydra Scripts\\n","permalink":"/head-protocol/adr/14"},"nextItem":{"title":"16. Keep Rejected ADRs\\n","permalink":"/head-protocol/adr/16"}},"content":"## Status\\n\\nProposed\\n\\n## Context\\n\\n* Hydra-node currently requires a whole slew of command-line arguments to configure properly its networking layer: `--peer` to connect to each peer, `--cardano-verification-key` and `--hydra-verification-key` to identify the peer on the L1 and L2 respectively.\\n* This poses significant challenges for operating a _cluster_ of Hydra nodes as one needs to know beforehand everything about the cluster, then pass a large number of arguments to some program or docker-compose file, before any node can be started\\n  * This is a pain that\'s been felt first-hand for benchmarking and testing purpose\\n* Having static network configuration is probably not sustainable in the long run, even if we don\'t add any fancy multihead capabilities to the node, as it would make it significantly harder to have automated creation of Heads.\\n* There\'s been an [attempt](https://github.com/cardano-scaling/hydra/pull/222) at providing a file-based network configuration but this was deemed unconvincing\\n* [Hydra paper (sec. 4, p. 13)](https://eprint.iacr.org/2020/299.pdf) explicitly assumes the existence of a _setup_ phase\\n  * This _setup_ is currently left aside, e.g. exchange of keys for setting up multisig and identifying peers. The [hydra-node](https://github.com/cardano-scaling/hydra/blob/abailly-iohk/admin-api-adr/hydra-node/exe/hydra-node/Main.hs#L41) executable is statically configured and those things are assumed to be known beforehand\\n\\n## Decision\\n\\n* Hydra-node exposes an _Administrative API_ to enable configuration of the Hydra network using \\"standard\\" tools\\n  * API is exposed as a set of HTTP endpoints on some port, consuming and producing JSON data,\\n  * It is documented as part of the User\'s Guide for Hydra Head\\n* This API provides _commands_ and _queries_ to:\\n  * Add/remove _peers_ providing their address and keys,\\n  * List currently known peers and their connectivity status,\\n  * Start/stop/reset the Hydra network\\n* This API is implemented by a _new component_ accessible through a network port separate from current _Client API_, that _configures_ the `Network` component\\n\\nThe following picture sketches the proposed architectural change:\\n\\n![Architecture change](img/0015-architecture-change.jpg)\\n\\n## Q&A\\n\\n* *Why a REST interface?*\\n  * This API is an interface over a specific _resource_ controlled by the Hydra node, namely its knowledge of other peers with which new _Head_s can be opened. As such a proper REST interface (_not_ RPC-in-disguise) seems to make sense here, rather than stream/event-based [duplex communication channels](/adr/3)\\n  * We can easily extend such an API with WebSockets to provide notifications (e.g. peers connectivity, setup events...)\\n* *Why a separate component?*\\n  * We could imagine extending the existing [APIServer](https://github.com/cardano-scaling/hydra/blob/9129c7c013fe2cdc77db048a54981e1ace0843b8/hydra-node/src/Hydra/API/Server.hs) interface with new messages related to this network configuration, however this seems to conflate different responsibilities in a single place: Configuring and managing the Hydra node itself, and configuring, managing, and interacting with the Head itself\\n  * \\"Physical\\" separation of endpoints makes it easier to secure a very sensitive part of the node, namely its administration, e.g by ensuring this can only be accessed through a specific network interface, without relying on application level authentication mechanisms\\n\\n## Consequences\\n\\n* It\'s easy to deploy Hydra nodes with some standard configuration, then dynamically configure them, thus reducing the hassle of defining and configuring the Hydra network\\n* It makes it possible to _reconfigure_ a Hydra node with different peers\\n* The _Client API_ should reflect the state of the network and disable `Init`ing a head if the network layer is not started\\n  * In the long run, it should also have its scope reduced to represent only the possible interactions with a _Head_, moving things related to network connectivity and setup to the Admin API\\n  * In a _Managed Head_ scenario it would even make sense to have another layer of separation between the API to manage the life-cycle of the Head and the API to make transactions within the Head\\n* Operational tools could be built easily on top of the API, for command-line or Web-based configuration"},{"id":"16","metadata":{"permalink":"/head-protocol/adr/16","source":"@site/adr/2022-03-23_016-keep-rejected-adr.md","title":"16. Keep Rejected ADRs\\n","description":"Status","date":"2022-03-23T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":0.72,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"16","title":"16. Keep Rejected ADRs\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"15. Configuration Through an Admin API\\n","permalink":"/head-protocol/adr/15"},"nextItem":{"title":"17. Use UDP protocol for Hydra networking\\n","permalink":"/head-protocol/adr/17"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nWe have started using _Architecture Decision Records_ as our primary way to document the most important design decisions we take while developing Hydra Node, and this has proved effective in fostering fruitful discussions about major architecture changes.\\n\\nDuring the course of this project, we have sometimes had debates on various topics leading to rejection of [some ADRs](https://github.com/cardano-scaling/hydra/pull/230). It could be the case that  a previously rejected proposal turns out to be interesting, either because the context and situation have changed enough to reevaluate a proposal, or as background for some new proposal.\\n\\n## Decision\\n\\n_therefore_\\n\\n* We will keep rejected _Architecture Decision Records_ alongside accepted and draft ones, in the same location and format\\n* Rejected ADRs _must_ have tag `[Rejected]` set\\n\\n## Consequences\\n\\nOnce attributed a _serial number_ an ADR keeps it \\"forever\\", whether it\'s rejected or accepted"},{"id":"17","metadata":{"permalink":"/head-protocol/adr/17","source":"@site/adr/2022-03-28_017-udp-networking.md","title":"17. Use UDP protocol for Hydra networking\\n","description":"Status","date":"2022-03-28T00:00:00.000Z","tags":[{"inline":true,"label":"Superseded","permalink":"/head-protocol/adr/tags/superseded"}],"readingTime":1.53,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"17","title":"17. Use UDP protocol for Hydra networking\\n","authors":[],"tags":["Superseded"]},"unlisted":false,"prevItem":{"title":"16. Keep Rejected ADRs\\n","permalink":"/head-protocol/adr/16"},"nextItem":{"title":"18. Single state in Hydra.Node.\\n","permalink":"/head-protocol/adr/18"}},"content":"## Status\\n\\nSuperseded (as never implemented) by [ADR 32](/adr/32)\\n\\n## Context\\n\\nCurrent Hydra networking layer is based on [Ouroboros network framework](https://github.com/input-output-hk/ouroboros-network/tree/master/ouroboros-network-framework) networking stack which, among other features, provides:\\n1. An abstraction of stream-based duplex communication channels called a [Snocket](https://github.com/input-output-hk/ouroboros-network/blob/6c15a8093bac34091ad96af2b8b0d1f7fe54b732/ouroboros-network-framework/src/Ouroboros/Network/Snocket.hs),\\n2. A Multiplexing connection manager that manages a set of equivalent peers, maintains connectivity, and ensures diffusion of messages to/from all peers,\\n2. Typed protocols for expressing the logic of message exchanges as a form of _state machine_.\\n\\nWhile it\'s been working mostly fine so far, the abstractions and facilities provided by this network layer are not well suited for Hydra Head networking. Some of the questions and shortcomings are discussed in a document on [Networking Requirements](/docs/dev/architecture/networking), and as the Hydra Head matures it seems time is ripe for overhauling current network implementation to better suite current and future Hydra Head networks needs.\\n\\n## Decision\\n\\n* Hydra Head nodes communicate by sending messages to other nodes using [UDP](https://en.wikipedia.org/wiki/User_Datagram_Protocol) protocol\\n\\n## Details\\n\\n* _How do nodes know each other?_: This is unspecified by this ADR and left for future work, it is assumed that a Hydra node operator knows the IP:Port address of its peers before opening a Head with them\\n* _Are messages encrypted?_: This should probably be the case in order to ensure Heads\' privacy but is also left for future work\\n* _How are nodes identified?_: At the moment they are identified by their IP:Port pair. As we implement more of the setup process from section 4 of the Hydra Head paper, we should identify nodes by some public key(hash) and resolve the actual IP:Port pair using some other mechanism\\n\\n## Consequences\\n\\n* Node\'s _HeadLogic_ handles lost, duplicates, and out-of-order messages using _retry_ and _timeout_ mechanisms\\n* Messages should carry a unique identifier, eg. source node and index\\n* Protocol, eg. messages format, is documented"},{"id":"18","metadata":{"permalink":"/head-protocol/adr/18","source":"@site/adr/2022-04-13_018-single-state.md","title":"18. Single state in Hydra.Node.\\n","description":"Status","date":"2022-04-13T00:00:00.000Z","tags":[{"inline":true,"label":"Superseded","permalink":"/head-protocol/adr/tags/superseded"}],"readingTime":3.735,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"18","title":"18. Single state in Hydra.Node.\\n","authors":[],"tags":["Superseded"]},"unlisted":false,"prevItem":{"title":"17. Use UDP protocol for Hydra networking\\n","permalink":"/head-protocol/adr/17"},"nextItem":{"title":"19. Use of reference scripts\\n","permalink":"/head-protocol/adr/19"}},"content":"## Status\\n\\nSuperseded by [ADR 23](/adr/23) and [ADR 26](/adr/26)\\n\\n## Context\\n\\n* Currently the `hydra-node` maintains two pieces of state during the life-cycle of a Hydra Head:\\n  1. A `HeadState tx` provided by the `HydraHead tx m` handle interface and part of the `Hydra.Node` module. It provides the basis for the main `hydra-node` business logic in `Hydra.Node.processNextEvent` and `Hydra.HeadLogic.update`\\n  [Creation](https://github.com/cardano-scaling/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Node.hs#L256-L257), [Usage](https://github.com/cardano-scaling/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Node.hs#L174)\\n  2. `SomeOnChainHeadState` is kept in the `Hydra.Chain.Direct` to keep track of the latest known head state, including notable transaction outputs and information how to spend it (e.g. scripts and datums)\\n  [Code](https://github.com/cardano-scaling/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Chain/Direct.hs#L156-L162), [Usage 1](https://github.com/cardano-scaling/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Chain/Direct.hs#L449), [Usage 2](https://github.com/cardano-scaling/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Chain/Direct.hs#L414), [Usage 3](https://github.com/cardano-scaling/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Chain/Direct.hs#L349-L352)\\n  (There are other unrelated things kept in memory like the event history in the API server or a peer map in the network heartbeat component.)\\n* The interface between the `Hydra.Node` and a `Hydra.Chain` component consists of \\n  - constructing certain Head protocol transactions given a description of it (`PostChainTx tx`):\\n    ```hs\\n    postTx :: MonadThrow m => PostChainTx tx -> m ()\\n    ```\\n  - a callback function when the `Hydra.Chain` component observed a new Head protocol transaction described by `OnChainTx tx`:\\n    ```hs\\n    type ChainCallback tx m = OnChainTx tx -> m ()\\n    ```\\n* Given by the usage sites above, the `Hydra.Chain.Direct` module requires additional info to do both, construct protocol transactions with `postTx` as well as observe potential `OnChainTx` ([here](https://github.com/cardano-scaling/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Chain/Direct.hs#L333-L336)). Hence we see that, operation of the `Hydra.Chain.Direct` component (and likely any implementing the interface fully) is **inherently stateful**.\\n* We are looking at upcoming features to [handle rollbacks](https://github.com/cardano-scaling/hydra/issues/185) and dealing with [persisting the head state](https://github.com/cardano-scaling/hydra/issues/187).\\n  - Both could benefit from the idea, that the `HeadState` is just a result of pure `Event` processing (a.k.a event sourcing).\\n  - Right now the `HeadState` kept in `Hydra.Node` alone, is not enough to fully describe the state of the `hydra-node`. Hence it would not be enough to just persist all the `Event`s and replaying them to achieve persistence, nor resetting to some previous `HeadState` in the presence of a rollback.\\n\\n## Decision\\n\\n* We define and keep a \\"blackbox\\" `ChainStateType tx` in the `HeadState tx`\\n  - It shall not be introspectable to the business logic in `HeadLogic`\\n  - It shall contain chain-specific information about the current Hydra Head, which will naturally need to evolve once we have multiple Heads in our feature scope\\n  - For example:\\n  ```hs\\n  data HeadState tx\\n    = IdleState\\n    | InitialState\\n        { chainState :: ChainStateType tx\\n        -- ...\\n        }\\n    | OpenState\\n        { chainState :: ChainStateType tx\\n        -- ...\\n        }\\n    | ClosedState\\n        { chainState :: ChainStateType tx\\n        -- ...\\n        }\\n  ```\\n* We provide the latest `ChainStateType tx` to `postTx`:\\n  ```hs\\n  postTx :: ChainStateType tx -> PostChainTx tx -> m ()\\n  ```\\n* We change the `ChainEvent tx` data type and callback interface of `Chain` to:\\n  ```hs\\n  data ChainEvent tx\\n    = Observation\\n        { observedTx :: OnChainTx tx\\n        , newChainState :: ChainStateType tx\\n        }\\n    | Rollback ChainSlot\\n    | Tick UTCTime\\n\\n  type ChainCallback tx m = (ChainStateType tx -> Maybe (ChainEvent tx)) -> m ()\\n  ```\\nwith the meaning, that invocation of the callback indicates receival of a transaction which is `Maybe` observing a relevant `ChainEvent tx`, where an `Observation` may include a `newChainState`.\\n* We also decide to extend `OnChainEffect` with a `ChainState tx` to explicitly\\n  thread the used `chainState` in the `Hydra.HeadLogic`.\\n\\n## Consequences\\n\\n* We need to change the construction of `Chain` handles and the call sites of `postTx`\\n* We need to extract the state handling (similar to the event queue) out of the `HydraNode` handle and shuffle the main of `hydra-node` a bit to be able to provide the latest `ChainState` to the chain callback as a continuation.\\n* We need to make the `ChainState` serializable (`ToJSON`, `FromJSON`) as it will be part of the `HeadState`.\\n* We can drop the `TVar` of keeping `OnChainHeadState` in the `Hydra.Chain.Direct` module.\\n* We need to update `DirectChainSpec` and `BehaviorSpec` test suites to mock/implement the callback & state handling.\\n* We might be able to simplify the `ChainState tx` to be just a `UTxOType tx` later.\\n* As `OnChainEffect` and `Observation` values will contain a `ChainStateType tx`, traces will automatically include the full `ChainState`, which might be helpful but also possible big. \\n\\n## Alternative\\n\\n* We could extend `PostChainTx` (like `Observation`) with `ChainState` and keep the signatures:\\n```hs\\npostTx :: MonadThrow m => PostChainTx tx -> m ()\\ntype ChainCallback tx m = (ChainState tx -> Maybe (ChainEvent tx) -> m ()\\n```\\n  - Not implemented as it is less clear on the need for a `ChainState` in the signatures."},{"id":"19","metadata":{"permalink":"/head-protocol/adr/19","source":"@site/adr/2022-07-22_019-reference-scripts.md","title":"19. Use of reference scripts\\n","description":"Status","date":"2022-07-22T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":3.01,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"19","title":"19. Use of reference scripts\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"18. Single state in Hydra.Node.\\n","permalink":"/head-protocol/adr/18"},"nextItem":{"title":"20. Handling time\\n","permalink":"/head-protocol/adr/20"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* In the desire to make Hydra transactions smaller and cheaper (at the time of writing any abort tx was too big), we want to use the **reference script** and **reference input** features of the upcoming `Babbage` ledger era. See the [babbage ledger spec](https://hydra.iohk.io/build/16861604/download/1/babbage-changes.pdf), [CIP-31](https://github.com/cardano-foundation/CIPs/tree/master/CIP-0031) and [CIP-33](https://github.com/cardano-foundation/CIPs/tree/master/CIP-0033) for details.\\n\\n* With these features we do not need to (re-)include scripts in each transaction.\\n\\n* The CIPs do not specify how reference scripts are to be managed and we can see at least two options:\\n  1. Add them as outputs to the `init` transaction or prior that as part of each Hydra Head instance\\n  2. Post them out-of-band, separate to individual Head instances\\n\\n* Ownership of the outputs holding the scripts is to be considered. If these \\"reference outputs\\" are spent, they cannot be referred to anymore. This would mean all heads referring to them can be denied of service (DoS).\\n\\n* Each head will need to refer to the correct version of the hydra scripts. That is, consistent with the script hashes known to the `hydra-node`.\\n  + This is also related to the problem of managing script versions & updates.\\n  + Right now, the `hydra-node` is compiled against `hydra-plutus` to access compiled script content and hashes.\\n\\n* The general trade-off is: instead of paying ADA fees for scripts adding to the transaction size in _each_ transaction, ADA deposits will need to be put down to have scripts be part of the UTxO set in the ledger _once_.\\n\\n## Decision\\n\\n* Publish outputs holding Hydra scripts out-of-band (option 2), because\\n  + All scripts would not fit into the `init` transaction directly, we would need to post multiple.\\n  + Costs (deposits) would need to be paid for each head instance.\\n\\n* The scripts are stored at outputs addressed to some **unspendable** `v_publish` validator.\\n  + This is to avoid DoS risk and unnecessariy centralization\\n  + We have considered \\"garbage collection\\" by allowing spending these outputs into re-publishing new versions of the script.\\n    - This would make things even more complicated and we decided to not bother about \\"littering the chain\\" right now.\\n\\n* We will publish scripts on release of the `hydra-node`, or more specifically of the `hydra-plutus` package.\\n\\n## Consequences\\n\\n* We need a process and/or tool to publish `hydra-plutus` scripts and need to pay the deposits.\\n  + Any other party could do the same, this does not lead to centralization.\\n\\n* The `hydra-node` would be need to know the `TxIn`s of the \\"right\\" published scripts.\\n  + In the simplest case we would just make this configurable and provide configurations for the various networks after publishing scripts.\\n\\n* If we combine the `v_publish` validator with a \\"tag\\", this allows nodes to \\"discover\\" scripts of a known version \\n  + For example, we could define `HydraHeadV1`, `HydraInitialV1` and `HydraCommitV1` as such tags\\n  + We could parameterize the validator by the tag, yielding unique addresses per tag.\\n  + Alternatively, the \\"tag\\" could be stored in a canonical form as datum on the script outputs. \\n  + In any case, this allows for some checking consistency or easier configuration (not needing to enumerate which `TxIn` is which script)\\n\\n* By also knowing the script hashes the `hydra-node` can verify the integrity of \\"found\\" reference scripts\\n  + This would be possible right now, as they are compiled into the node\\n  + Might be undesirable later for easier system configuration\\n\\n* By making `v_publish` unspendable, we \\"litter\\" the chain. However, any garbage collection scheme would mean potential to DoS again.\\n\\n* Extended diagram for the [abort](img/on-chain-abort-reference-scripts.jpg) on-chain life-cycles of a Hydra Head to include reference scripts."},{"id":"20","metadata":{"permalink":"/head-protocol/adr/20","source":"@site/adr/2022-08-02_020-handling-time.md","title":"20. Handling time\\n","description":"Status","date":"2022-08-02T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":3.55,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"20","title":"20. Handling time\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"19. Use of reference scripts\\n","permalink":"/head-protocol/adr/19"},"nextItem":{"title":"21. Bounded transaction validity on Hydra protocol transactions\\n","permalink":"/head-protocol/adr/21"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* The Hydra Head protocol is expected to be isomorphic to the ledger it runs on. That means, it should support the same transaction formats and (if desired) use the same ledger rules as the layer 1.\\n\\n* Cardano is our layer 1 and its consensus layer separates time into discrete steps, where each step is called a `Slot`. The network is expected to evolve strictly monotonically on this time scale and so slot numbers (`SlotNo`) are always increasing.\\n\\n* The Cardano mainnet has a block scheduled every 20 seconds, although it may take longer.\\n  - This is because `slotLength = 1.0` and every 20th slot is \\"active\\" with `f = 0.05`.\\n  - The consensus protocol requires `k` blocks to be produced within `3k/f` slots, where `k = 2160` on mainnet.\\n\\n* Transactions on Cardano may have a validity range with a lower and upper bound given as `SlotNo`.\\n\\n* Wall-clock time can be converted to slots (and back) using an `EraHistory` or `EpochInterpreter` provided by the consensus layer of the cardano node. This is required as the slot lengths could change over time.\\n  - All past points in time since the `SystemStart` can be converted.\\n  - Future points in time can **only** be converted in the \\"safe zone\\", practically being at least `3k/f` slots (TODO: cross check). Refer to chapter 17 *Time* on the [consensus spec](https://hydra.iohk.io/build/16997794/download/1/report.pdf) for more details.\\n\\n* The Hydra Head protocol allows `close` and `contest` transactions only up before a deadline `T_final`, and `fanout` transactions after the deadline.\\n  - In the current implementation the deadline is upper validity of `closed` plus the contestation period.\\n  - We also consider protocol variants which push out the deadline by the contestation period on each `contest`.\\n  - Contestation periods may very well be longer than the stability window of the protocol. For example: 7 days, while the mainnet stability window is more like 36 hours.\\n\\n* We have encountered two problems with handling time in the past\\n  - Trying to convert wall-clock time to slots of the Head protocol deadline led to `PastHorizonException` (when using very low security parameter `k`)\\n  - Trying to `fanout` after the deadline, but before another block has been seen by the L1 ledger led to `OutsideValidityIntervalUTxO`.\\n  \\n* The second problem scenario and solution ideas are roughly visible on this whiteboard:\\n\\n![](img/020-timing-fanout.jpg)\\n\\n## Decision\\n\\n* The head logic uses wall-clock time to track time and only convert to/from slots when constructing/observing transactions in the chain layer.\\n  - This ensures that transactions we post or see on the chain can be converted to/from slots.\\n  - The head logic would use `UTCTime` for points in time and `NominalDiffTime` for durations.\\n  - The chain layer converts these using the `SystemStart` and `EraHistory` into `SlotNo`.\\n\\n* The chain layer informs the logic layer whenever time passed (on the chain) using a new `Tick` event.\\n  - For the direct chain implementation, this is whenever we see a block in the chain sync protocol.\\n  - Per above decision, the `Tick` shall contain a `UTCTime` corresponding to the new \\"now\\" as seen through the block chain.\\n\\n## Consequences\\n\\n* Conversion from `UTCTime -> SlotNo` and vice versa stays local to the chain layer.\\n\\n* The `HeadLogic` can track chain time in its state and condition `ReadyToFanout` upon seeing it pass the deadline.\\n  - Ensures clients only see `ReadyToFanout` when a following `Fanout` would be really possible.\\n  - Makes the `Delay` effect redundant and we can remove it (only delay via reenqueue on the `Wait` outcome)\\n\\n* By introducing `Tick` events, `IOSim` will not be able to detect non-progress (deadlocks).\\n  - This means we cannot rely on early exit of simulations anymore and need to determine meaningful simulation endings instead of `waitUntilTheEndOfTime`.\\n\\n* We get a first, rough notion of time for free in our L2 and can support \\"timed transactions\\" with same resolution as the L1.\\n  - Tracking time in the state makes it trivial to provide it to the ledger when we `applyTransaction`.\\n  - Of course we could extend the fidelity of this feature using the system clock for \\"dead reckoning\\" between blocks. The conversion of wall clock to slot could even be configurable using an L2 `slotLength` analogous to L1 (although we might not want/need this)."},{"id":"21","metadata":{"permalink":"/head-protocol/adr/21","source":"@site/adr/2022-12-05_021-Bounded-transaction-validity-on-Hydra-protocol-transactions.md","title":"21. Bounded transaction validity on Hydra protocol transactions\\n","description":"Status","date":"2022-12-05T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":2.81,"hasTruncateMarker":false,"authors":[{"name":"Sebastian Nagel","title":"Software Engineering Lead","url":"https://github.com/ch1bo","imageURL":"https://github.com/ch1bo.png","key":"ch1bo","page":null},{"name":"Pascal Grange","title":"Senior Software Engineer","url":"https://github.com/pgrange","imageURL":"https://github.com/pgrange.png","key":"pgrange","page":null},{"name":"Franco Testagrossa","title":"Senior Software Engineer","url":"https://github.com/ffakenz","imageURL":"https://github.com/ffakenz.png","key":"ffakenz","page":null},{"name":"Arnaud Bailly","title":"Lead Architect","url":"https://github.com/abailly-iohk","imageURL":"https://github.com/abailly-iohk.png","key":"abailly","page":null},{"name":"Sasha Bogicevic","title":"Senior Software Engineer","url":"https://github.com/v0d1ch","imageURL":"https://github.com/v0d1ch.png","key":"v0d1ch","page":null}],"frontMatter":{"slug":"21","title":"21. Bounded transaction validity on Hydra protocol transactions\\n","authors":["ch1bo","pgrange","ffakenz","abailly","v0d1ch"],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"20. Handling time\\n","permalink":"/head-protocol/adr/20"},"nextItem":{"title":"22. Test High-level Properties using Model-Based Testing\\n","permalink":"/head-protocol/adr/22"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n- The HydraHeadV1 formal specification contains a _bounded confirmation window_:\\n\\n  ```\\n  // Deadline\\n\\n  T_max <= T_min + L // Bounded confirmation window\\n  DL\u2019 = T_max + L    // The latest possible deadline is 2*L\\n\\n  ```\\n\\n  with `T_min` and `T_max` being the tx validity bounds and `L` being the\\n  contestation period.\\n\\n  - This is to avoid attacks with specified upper validity bound being too far\\n    in the future and denial of service the head with this (e.g. 10 years).\\n\\n#### Current state of things:\\n\\n- The contestation period and upper tx validity is used for computing the\\n  contestation deadline.\\n\\n- There is a `closeGraceTime` currently hard-coded (to `100` slots) to set some\\n  upper bound on the `closeTx`. This was also required so far to compute the\\n  contestation deadline.\\n\\n- Different networks (chains) have different slot lengths, e.g. the preview\\n  network has a slot every `1s`, while our local devnets use `0.1s`. This means\\n  hardcoded values like `closeGraceTime` need to be _in sync_ with the\\n  underlying network.\\n\\n- The `contestationPeriod` can be configured by users via the `Init` client\\n  input. For example, the hydra-cluster test suite uses a hardcoded `cperiod` on\\n  the client side.\\n\\n- Default value for `T_Min` is negative infinity.\\n\\n- Lower tx validity being in the future does not pose a problem since other\\n  participant is able to close a head.\\n\\n#### What we want to achieve:\\n\\n- We want to enforce topmost formula in this file in our code on-chain.\\n\\n- Introduce `maxGraceTime` expressed in seconds in place of `closeGraceTime` and adjust to\\n  appropriate value.\\n\\n- The contestation period is to be used to create bounded close transaction\\n  (together with `maxGraceTime`). Before it was only used for computing the\\n  contestation deadline.\\n\\n- [x] If contestation period is higher than `maxGraceTime` we will pick the\\n      latter. We still need `maxGraceTime` since if `contestationPeriod` is low for\\n      the current network our txs reach the upper bound fast and become invalid.\\n      That is why we set the upper tx bound to be minimum between\\n      `contestationPeriod` and `maxGraceTime` so that txs have high enough upper\\n      bound.\\n\\n- Make sure all head participants use the same value for `contestationPeriod`.\\n\\n- Attack vector has a corresponding mutation test.\\n\\n## Decision\\n\\n- Use the specification formula on-chain.\\n\\n- Configure the contestation period (number of seconds) on the `hydra-node`,\\n  e.g. via a `--contestation-period` command line option.\\n\\n- Lower tx bound should be the last known slot as reported by the\\n  `cardano-node`.\\n\\n- Upper tx bound is the current time + minimum between `contestationPeriod` and\\n  `maxGraceTime`.\\n\\n- When submitting the `InitTx` make sure to use `--contestation-period` value\\n  from our node\'s flag.\\n\\n- If other nodes observe `OnInitTx` and the `contestationPeriod` value does not\\n  match with their `--contestation-period` setting - ignore `InitTx`.\\n\\n- Rename `closeGraceTime` to `maxGraceTime` since we are using it also for upper\\n  bound of a contest tx.\\n\\n## Consequences\\n\\n- Not any positive number of seconds is a valid contestation period any more!\\n\\n- Upper tx validity of close transaction is the minimum between `maxGraceTime`\\n  and `contestationPeriod` and this needs to be _good enough_ value with respect\\n  to running network. This is a consequence required by the ledger when\\n  constructing transactions since we cannot convert arbitrary point in times to\\n  slots.\\n\\n- All parties need to agree on contestation period before trying to run a Head\\n  protocol otherwise InitTx will be ignored."},{"id":"22","metadata":{"permalink":"/head-protocol/adr/22","source":"@site/adr/2022-12-06_022-model-based-testing.md","title":"22. Test High-level Properties using Model-Based Testing\\n","description":"Status","date":"2022-12-06T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.805,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"22","title":"22. Test High-level Properties using Model-Based Testing\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"21. Bounded transaction validity on Hydra protocol transactions\\n","permalink":"/head-protocol/adr/21"},"nextItem":{"title":"23. Local chain state in chain layer\\n","permalink":"/head-protocol/adr/23"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n- We have been experimenting with [quickcheck-dynamic](https://hackage.org/packages/quickcheck-dynamic) for a while, leading to the implementation of basic [Model-Based tests](https://github.com/cardano-scaling/hydra/blob/master/hydra-node/test/Hydra/ModelSpec.hs) for the Hydra Head Protocol\\n- These tests fill a gap in our testing strategy, between [BehaviorSpec](https://github.com/cardano-scaling/hydra/blob/master/hydra-node/test/Hydra/BehaviorSpec.hs) tests which test a \\"network\\" of nodes but only at the level of the off-chain Head logic, and [EndToEndSpec](https://github.com/cardano-scaling/hydra/blob/master/hydra-cluster/test/Test/EndToEndSpec.hs) tests which test a full blown network of nodes interconnected through real network connections and to a real cardano-node:\\n  - The former are fast but do not test the complete lifecycle of a Head. Furthermore, they are only unit tests so do not provide coverage into various corner cases that could arise in practice\\n  - The latter exercise the full lifecycle but are very slow and brittle\\n- Because they run in [io-sim](https://github.com/input-output-hk/io-sim), those Model-based tests are fast and robust as they don\'t depend on system interactions. Moreover, decoupling the _System-under-Test_ from `IO` makes it easy to simulate an environment that deviates from the \\"happy path\\" such as delays from the network, filesystem errors, or even adversarial behaviour from the node, or the chain.\\n\\n## Decision\\n\\n- We will maintain and evolve the [Model](https://github.com/cardano-scaling/hydra/blob/master/hydra-node/test/Hydra/Model.hs) over time to cover more features\\n- Key properties of the whole system should be written-down as proper `DynamicLogic` properties and thoroughly tested using quickcheck-dynamic. This includes but is not limited to:\\n  - Liveness of the Head\\n  - Consistency of the Head\\n  - Soundness of Chain\\n  - Completeness of Chain\\n\\n## Consequences\\n\\n- We need to ensure the Model covers the full lifecycle of a Hydra Head network which at the time of writing this ADR is not the case\\n- There cannot be _One Model to Rule Them All_ so we should refrain from defining different `StateModel` or different `RunModel` depending on what needs to be tested\\n- In particular, testing against adversarial conditions will certainly require defining different instances of the `Network` or `Chain` components, for example:\\n  - An _Accepted Adversary_ that fully the controls the protocol and the parties,\\n  - A _Network Adversary_ that can delay and or drop messages,\\n  - A _Faulty Filesystem_ that can causes exceptions when reading or writing files,\\n  - ..."},{"id":"23","metadata":{"permalink":"/head-protocol/adr/23","source":"@site/adr/2023-04-26_023-local-chain-state.md","title":"23. Local chain state in chain layer\\n","description":"Status","date":"2023-04-26T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.99,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"23","title":"23. Local chain state in chain layer\\n","authors":[],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"22. Test High-level Properties using Model-Based Testing\\n","permalink":"/head-protocol/adr/22"},"nextItem":{"title":"24. Persist state changes incrementally\\n","permalink":"/head-protocol/adr/24"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n- [ADR 18](/adr/18) merged both `headState` and `chainState` into one single\\n  state in the Hydra node, giving the chain layer a way to _fetch_ and update\\n  the `chainState` when observing a chain event.\\n- Having the `headState` containing the `chainState` made persistency easier to\\n  deal with: we ensure that we always save cohesive states.\\n- When opening our first head on mainnet we suffered from a [commit/rollback\\n  issue](https://github.com/cardano-scaling/hydra/issues/784) that was the\\n  result of a race condition in the management of the `chainState` as implemented\\n  in the context of [ADR 18](/adr/18).\\n- Reproducing the issue by introducing rollbacks in the model based tests, we\\n  discovered that, as a client of a hydra-node, we had no idea how to deal with\\n  the rollback event as it is defined now.\\n- [#185](https://github.com/cardano-scaling/hydra/issues/185) plans to improve\\n  rollback management.\\n\\nThe following picture details the race condition through an example:\\n\\n1. The DirectChain component fetch some `chainState 0` from the `headState`\\n\\n1. The DirectChain component observes a transaction and it\\n\\n- publishes an event about this observation\\n- updates the `headState` with some `chainState 1`\\n\\n1. The Node processes the event and emits a new `headState` with a\\n   `previousRecoverableState` in case a rollback later happens\\n\\nThe problem is that `HeadState 2` in the figure should point to a previous\\nrecoverable head state containing `chainState 0` and not `chainState 1`.\\n\\n![race condition](2023-04-26-023-race-condition.jpg)\\n\\nUpdating the chain state only in the `HeadLogic` leads to problems when several\\ntransactions are in the same block. This can be mitigated by keeping a volatile\\nchain state locally while analysing the block. But then it leads to race\\nconditions issues if, for some reason, blocks are produced faster than they are\\nprocessed by the HeadLogic. Low probability in production but higher when\\ntesting.\\n\\n## Decision\\n\\n- We supersede [ADR 18](/adr/18) with the current ADR.\\n- A local chain state is re-introduced in the chain component, not shared with\\n  the head logic.\\n- A copy of the `chainState` is kept in the `headState` to keep the benefits of\\n  [ADR 18](/adr/18) regarding persistency.\\n- The `RolledBack` output is removed from the API unless actionable by users or\\n  [#185](https://github.com/cardano-scaling/hydra/issues/185) implemented.\\n\\n## Consequences\\n\\n- The rollback logic is removed from the HeadLogic and only maintained in the\\n  chain component.\\n- The Rollback event carries the ChainState.\\n- At the node startup, we initialize the chain layer with the persisted\\n  `chainState`"},{"id":"24","metadata":{"permalink":"/head-protocol/adr/24","source":"@site/adr/2023-06-19_024-event-sourced-persistence.md","title":"24. Persist state changes incrementally\\n","description":"Status","date":"2023-06-19T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":2.47,"hasTruncateMarker":false,"authors":[{"name":"Arnaud Bailly","title":"Lead Architect","url":"https://github.com/abailly-iohk","imageURL":"https://github.com/abailly-iohk.png","key":"abailly","page":null}],"frontMatter":{"slug":"24","title":"24. Persist state changes incrementally\\n","authors":["abailly"],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"23. Local chain state in chain layer\\n","permalink":"/head-protocol/adr/23"},"nextItem":{"title":"25. Event-sourced, resource-based API\\n","permalink":"/head-protocol/adr/25"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n- The state of a Hydra Head is currently persisted as a whole upon each `NewState` _outcome_ from the `update` function: The new state is serialised and the `state` file is overwritten with the corresponding bytes. While this is a straightforward strategy to implement, it has a huge impact on the performance of a Hydra Head as serialising a large data structure like the `HeadState` and completely overwriting a file is costly\\n  - We revisited our benchmarks and [found](https://github.com/cardano-scaling/hydra/issues/186#issuecomment-1584292265) that persistence was the major bottleneck when measuring roundtrip confirmation time,e g. the time it takes from a client\'s perspective to submit a transaction and observe in a `ConfirmedSnapshot`\\n- Furthermore, the way we currently handle changes to the `HeadState` in the hydra-node, while conceptually being an `Effect` is handled differently from other `Effect`s: The state is updated transactionally through a dedicated `modifyHeadState` function in the core loop of processing events, and _then_ effects are processed.\\n\\n## Decision\\n\\nImplement state persistence using [_Event Sourcing_](https://thinkbeforecoding.com/post/2013/07/28/Event-Sourcing-vs-Command-Sourcing). Practically, this means:\\n\\n1. Replace the `NewState` outcome with a `StateChanged` _event_ which can be part of the `Outcome` of `HeadLogic`\'s `update` function, representing the _change_ to be applied to the current state.\\n2. Add an `aggregate` function to manage applying `StateChanged` events on top of the current `HeadState` to keep it updated in-memory.\\n3. Persist `StateChanged`s in an append-only log using a dedicated [handle](/adr/4).\\n4. Upon node startup, reread `StateChanged` events log and reapply those to reset the `HeadState`.\\n\\nThe following sequence diagram illustrates new event handling in the `HeadLogic`:\\n\\n```mermaid\\nsequenceDiagram\\n   Node ->> Node : nextEvent : event\\n   critical modifyHeadState : state -> state\';\\n     activate Node\\n     Node ->>+ HeadLogic: update(state, event)\\n     HeadLogic --\x3e>- Node : Outcome (sc: StateChanged, oe: OtherEffect)\\n     Node ->>+ HeadLogic: aggregate(state, sc)\\n     HeadLogic --\x3e- Node : state\'\\n   end\\n   deactivate Node\\n   Node ->> Persistence: append(sc)\\n   Node ->> Node: processEffect(oe)\\n```\\n\\n## Consequences\\n\\n- :racehorse: The main expected consequence of this change is an increase of the overall performance of Hydra Head network.\\n\\n- Need to pattern match twice on the `HeadState`, once in `update` and once in `aggregate`.\\n\\n- Terms from the specification are distributed over `update` and `aggregate` function. For example, the statements about updating all seen transactions would now be in `aggregate` and not anymore in `update`.\\n\\n- New possibilities this change introduces with respect to `ServerOutput` handling and client\'s access to a head\'s state:\\n\\n  - Instead of having the `HeadLogic` emits directly a `ClientEffect`, the latter could be the result of a client-centric _interpretation_ of a `StateChanged`.\\n  - Pushing this a little further, we could maintain a _Query Model_ for clients with a dedicated [Query API](https://github.com/cardano-scaling/hydra/discussions/686) to ease implementation of stateless clients.\\n\\n- Calling `StateChanged` an _event_ while treating it in the code alongside _effects_ might introduce some confusion as we already use the word [Event](https://github.com/cardano-scaling/hydra/blob/45913954eb18ef550a31017daa443cee6720a00c/hydra-node/src/Hydra/HeadLogic.hs#L64) to designate the inputs (a.k.a. commands) to the Head logic state machine. We might want at some later point to unify the terminology."},{"id":"25","metadata":{"permalink":"/head-protocol/adr/25","source":"@site/adr/2023-08-18_025-resource-based-api.md","title":"25. Event-sourced, resource-based API\\n","description":"Status","date":"2023-08-18T00:00:00.000Z","tags":[{"inline":true,"label":"Proposed","permalink":"/head-protocol/adr/tags/proposed"}],"readingTime":4.58,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"25","title":"25. Event-sourced, resource-based API\\n","authors":[],"tags":["Proposed"]},"unlisted":false,"prevItem":{"title":"24. Persist state changes incrementally\\n","permalink":"/head-protocol/adr/24"},"nextItem":{"title":"26. Stateless transaction observation & construction\\n","permalink":"/head-protocol/adr/26"}},"content":"## Status\\n\\nProposed\\n\\n## Context\\n\\n- [ADR-3](/adr/3) concluded that a full-duplex communication channels are\\n  desirable to interact with a _reactive_ system.\\n\\n- The Client API communicates several types of messages to clients. Currently\\n  this ranges from node-level `PeerConnected`, over head-specific `HeadIsOpen`\\n  to messages about transactions like `TxValid`. These messages are all of type\\n  `StateChanged`.\\n\\n- Current capabilities of the API:\\n\\n  - Clients can retrieve the whole history of `StateChanged` messages or\\n    opt-out using a query parameter - all or nothing.\\n\\n  - There is a welcome message called `Greetings` which is always sent, that\\n    contains the last `headStatus`.\\n\\n  - There exists a `GetUTxO` query-like `ClientInput`, which will respond with a\\n    `GetUTxOResponse` containing the confirmed UTxO set in an open head, or (!)\\n    the currently committed UTxO set when the head is initializing.\\n\\n  - While overall `json` encoded, clients can choose choose between `json` or\\n    binary (`cbor`) output of `transaction` fields in several of these using a\\n    query parameter.\\n\\n- Many of these features have been added in a \\"quick and dirty\\" way, by monkey\\n  patching the encoded JSON.\\n\\n- The current capabalities even do not satisfy all user needs:\\n\\n  - Need to wade through lots of events to know the latest state (except the\\n    very basic `headStatus` from the `Greetings`).\\n\\n  - Need to poll `GetUTxO` _or_ aggregate confirmed transactions on client side\\n    to know the latest UTxO set for constructing transactions.\\n\\n  - Inclusion of the whole UTxO set in the head is not always desirable and\\n    filtering by address would be beneficial. (not addressed in this ADR though,\\n    relevant discussion\\n    [#797](https://github.com/cardano-scaling/hydra/discussions/797))\\n\\n  - As [ADR-15](/adr/15) also proposes, some clients may not need (or should\\n    not have) access to administrative information.\\n\\n- It is often a good idea to separate the responsibilities of Commands and\\n  Queries ([CQRS](https://martinfowler.com/bliki/CQRS.html)), as well as the model they use.\\n\\n## Decision\\n\\n- Drop `GetUTxO` and `GetUTxOResponse` messages as they advocate a\\n  request/response way of querying.\\n\\n- Realize that `ClientInput` data is actually a `ClientCommand` (renaming them)\\n  and that `ServerOutput` are just `projections` of the [internal event stream\\n  (see ADR-24)](/adr/24) into read `models` on the API layer.\\n\\n- Compose a versioned (`/v1`) API out of resource `models`, which\\n  compartmentalize the domain into topics on the API layer.\\n\\n  - A resource has a `model` type and the _latest_ value is the result of a pure\\n    `projection` folded over the `StateChanged` event stream, i.e. `project :: model -> StateChanged -> model`.\\n\\n  - Each resource is available at some HTTP path, also called \\"endpoint\\":\\n\\n    - `GET` requests must respond with the _latest_ state in a single response.\\n\\n    - `GET` requests with `Upgrade: websocket` headers must start a websocket\\n      connection, push the _latest_ state as first message and any resource\\n      state updates after.\\n\\n    - Other HTTP verbs may be accepted by a resource handler, i.e. to issue\\n      resource-specific _commands_. Any commands accepted must also be available\\n      via the corresponding websocket connection.\\n\\n  - `Accept` request headers can be used to configure the `Content-Type` of the\\n    response\\n\\n    - All resources must provide `application/json` responses\\n\\n    - Some resources might support more content types (e.g. CBOR-encoded binary)\\n\\n  - Query parameters may be used to further configure responses of some\\n    resources. For example, `?address=<bech32>` could be used to filter UTxO by\\n    some address.\\n\\n- Keep the semantics of `/`, which accepts websocket upgrade connections and\\n  sends direct/raw output of `ServerOutput` events on `/`, while accepting all\\n  `ClientCommand` messages.\\n\\n  - Define `ServerOutput` also in terms of the `StateChanged` event stream\\n\\n### Example resources\\n\\nExample resource paths + HTTP verbs mapped to existing things to demonstrate the\\neffects of the decision points above. The mappings may change and are to be\\ndocumented by an API specification instead.\\n\\n| Path                             | GET                            | POST                   | PATCH   | DELETE             |\\n| :------------------------------- | :----------------------------- | :--------------------- | ------- | :----------------- |\\n| `/v1/head/status`                | `HeadStatus(..)`               | -                      | -       | -                  |\\n| `/v1/head/snapshot/utxo`         | last confirmed snapshot utxo   | -                      | -       | -                  |\\n| `/v1/head/snapshot/transactions` | confirmed snapshot txs         | `NewTx` + responses    | -       | -                  |\\n| `/v1/head/ledger/utxo`           | `localUTxO`                    | -                      | -       | -                  |\\n| `/v1/head/ledger/transactions`   | `localTxs`                     | `NewTx` + responses    | -       | -                  |\\n| `/v1/head/commit`                | -                              | `Chain{draftCommitTx}` | -       | -                  |\\n| `/v1/head`                       | all `/v1/head/*` data          | `Init`                 | `Close` | `Fanout` / `Abort` |\\n| `/v1/protocol-parameters`        | current protocol parameters    |                        |         |                    |\\n| `/v1/cardano-transaction`        | -                              | `Chain{submitTx}`      | -       | -                  |\\n| `/v1/peers`                      | a list of peers                | -                      | -       | -                  |\\n| `/v1/node-version`               | node version as in `Greetings` | -                      | -       | -                  |\\n| `/v1/`                           | all `/v1/*` data               | -                      | -       | -                  |\\n\\nMultiple heads are out of scope now and hence paths are not including a\\n`<headId>` variable section.\\n\\n## Consequences\\n\\n- Clear separation of what types are used for querying and gets subscribed to by\\n  clients and we have dedicated types for sending data to clients\\n\\n- Changes on the querying side of the API are separated from the business logic.\\n\\n- Clients do not need to aggregate data that is already available on the server\\n  side without coupling the API to internal state representation.\\n\\n- Separation of Head operation and Head usage, e.g. some HTTP endpoints can be\\n  operated with authentication.\\n\\n- Clients have a fine-grained control over what to subscribe to and what to\\n  query.\\n\\n- Versioned API allows clients to detect incompatibility easily.\\n\\n- Need to rewrite how the `hydra-tui` is implemented."},{"id":"26","metadata":{"permalink":"/head-protocol/adr/26","source":"@site/adr/2023-09-08_026-stateless-observation-construction.md","title":"26. Stateless transaction observation & construction\\n","description":"Status","date":"2023-09-08T00:00:00.000Z","tags":[{"inline":true,"label":"Proposed","permalink":"/head-protocol/adr/tags/proposed"}],"readingTime":3.74,"hasTruncateMarker":false,"authors":[{"name":"Sebastian Nagel","title":"Software Engineering Lead","url":"https://github.com/ch1bo","imageURL":"https://github.com/ch1bo.png","key":"ch1bo","page":null}],"frontMatter":{"slug":"26","title":"26. Stateless transaction observation & construction\\n","authors":["ch1bo"],"tags":["Proposed"]},"unlisted":false,"prevItem":{"title":"25. Event-sourced, resource-based API\\n","permalink":"/head-protocol/adr/25"},"nextItem":{"title":"27. Network failures model\\n","permalink":"/head-protocol/adr/27"}},"content":"## Status\\n\\nProposed\\n\\n## Context\\n\\n- [ADR 18](/adr/18) merged both `headState` and `chainState` into one single\\n  state in the Hydra node, giving the chain layer a way to _fetch_ and update\\n  the `chainState` when observing a chain event.\\n\\n- [ADR 23](/adr/23) outlined the need for a local chain state in the chain layer\\n  again to correctly handle correct observation of multiple relevant\\n  transactions and the resulting `chainState` updates.\\n\\n- The `ChainStateType tx` for our \\"actual\\" Cardano chain layer is currently:\\n\\n  ```haskell\\n  data ChainStateAt = ChainStateAt\\n    { chainState :: ChainState\\n    , recordedAt :: Maybe ChainPoint\\n    }\\n\\n  data ChainState\\n    = Idle\\n    | Initial InitialState\\n    | Open OpenState\\n    | Closed ClosedState\\n  ```\\n\\n  where `InitialState`, `OpenState` and `ClosedState` hold elaborate information\\n  about the currently tracked Hydra head.\\n\\n- We face [difficulties](https://github.com/cardano-scaling/hydra/issues/529) to\\n  provide sufficient user feedback when an `initTx` was observed but (for\\n  example) keys do not match our expectation.\\n\\n  - Core problem is, that `observeInit` is required to take a decision whether\\n    it wants to \\"adopt\\" the Head by returning an `InitialState` or not.\\n  - This makes it impossible to provide user feedback through the `HeadLogic`\\n    and `API` layers.\\n\\n- We want to build a [Hydra head\\n  explorer](https://github.com/cardano-scaling/hydra/issues/696), which should\\n  be able to keep track and discover Hydra heads and their state changes even\\n  when the heads were initialized before starting the explorer.\\n\\n## Decision\\n\\n- We supersede [ADR 18](/adr/18) with the current ADR.\\n\\n### Changes internal to Direct chain layer\\n\\n- Introduce a `ResolvedTx` type that has its inputs resolved. Where a normal\\n  `Tx` will only contain `TxIn` information of its inputs, a `ResolvedTx` also\\n  includes the `TxOut` for each input.\\n\\n- Change `ChainSyncHandler` signature to `onRollForward :: BlockHeader -> [ResolvedTx] -> m ()`\\n\\n- Change observing function signature to `observeSomeTx :: ChainContext ->\\n  ResolvedTx -> Maybe (OnChainTx Tx)`. Notably there is no `ChainState`\\n  involved.\\n\\n- Do not guard observation by `HeadId` in the chain layer and instead do it in the `HeadLogic` layer.\\n\\n- Define a `SpendableUTxO` type that is a `UTxO` with potentially needed datums included.\\n\\n  - TBD: instead we could decide to use inline datums and rely on `UTxO` containing them\\n\\n- Change transaction creation functions `initialize`, `commit`, `abort`,\\n  `collect`, `close`, `contest` and `fanout` in `Hydra.Direct.Chain.State` to\\n  take `SpendableUTxO` and `HeadId`/`HeadParameters` as needed.\\n\\n- Extend `IsChainState` type class to enforce that it can be updated by\\n  concurrent transactions `update :: ChainStateType tx -> [tx] -> ChainStateType tx`.\\n\\n  - While this is not strictly needed \\"outside\\" of the chain layer, it will have\\n    us not fall into the same pit again.\\n\\n- Change `ChainStateAt` to only hold a `spendableUTxO` and the `recordedAt`.\\n\\n- Update the `LocalChainState` in `onRollForward` by using `update` and pushing\\n  a new `ChainStateAt` generically.\\n\\nTBD:\\n\\n- Impact on generators\\n\\n### Chain interface changes\\n\\n- Add `HeadId` and `HeadParameters` to `PostChainTx`.\\n- Add `HeadId` to all `OnChainTx` constructors.\\n- Extend `OnInitTx` with observed chain participants.\\n\\n  - TBD: How are _cardano_ verification keys generically represented in `HeadLogic`?\\n\\n- Extend `OnContestTx` with new deadline and a list of contesters.\\n- Move off-chain checks for what makes a \\"proper head\\" to `HeadLogic`\\n\\nTBD:\\n\\n- Merge `HeadSeed` and `HeadId`? How to abstract?\\n\\n## Consequences\\n\\n- All logic is kept in the logic layer and no protocol decisions (i.e. whether\\n  to adopt or ignore a head initialization) are taken in the chain layer.\\n\\n  - The `HeadLogic` gets informed of any proper `initTx` and can log that it is\\n    ignored and for what reason.\\n\\n- The transaction observation and construction functions can be moved into a\\n  dedicated package that is cardano-specific, but not requires special state\\n  knowledge of the \\"direct chain following\\" and can be re-used as a library.\\n\\n- All transaction observation functions used by `observeSomeTx` will need to be\\n  able to identify a Hydra Head transaction from only the `ResolvedTx` and the\\n  `ChainContext`\\n\\n- Any `Chain Tx` implementation wanting to re-use existing transaction\\n  observation functions must be able to resolve transaction inputs (against some\\n  ledger state) and produce `ResolvedTx`.\\n\\n  - A chain-following implementation (as `Hydra.Chain.Direct`) can keep previous\\n    transactions around.\\n  - A chain indexer on \\"interesting\\" protocol addresses can be used to\\n    efficiently query most inputs.\\n\\n- We can get rid of the `Hydra.Chain.Direct.State` glue code altogether.\\n\\n- While this does not directly supersede [ADR23](/adr/23), it paves the way to\\n  remove `LocalChainState` again as the `ChainStateAt` is now combinable from\\n  multiple transactions (see `update` above) and we can keep the state (again)\\n  only in the `HeadState` aggregate. Note that this would shift the rollback\\n  handling back into the logic layer."},{"id":"27","metadata":{"permalink":"/head-protocol/adr/27","source":"@site/adr/2023-09-09_027-network-resilience.md","title":"27. Network failures model\\n","description":"Status","date":"2023-09-09T00:00:00.000Z","tags":[{"inline":true,"label":"Superseded","permalink":"/head-protocol/adr/tags/superseded"}],"readingTime":4.435,"hasTruncateMarker":false,"authors":[{"name":"Arnaud Bailly","title":"Lead Architect","url":"https://github.com/abailly-iohk","imageURL":"https://github.com/abailly-iohk.png","key":"abailly","page":null},{"name":"Pascal Grange","title":"Senior Software Engineer","url":"https://github.com/pgrange","imageURL":"https://github.com/pgrange.png","key":"pgrange","page":null}],"frontMatter":{"slug":"27","title":"27. Network failures model\\n","authors":["abailly","pgrange"],"tags":["Superseded"]},"unlisted":false,"prevItem":{"title":"26. Stateless transaction observation & construction\\n","permalink":"/head-protocol/adr/26"},"nextItem":{"title":"28. Offline mode\\n","permalink":"/head-protocol/adr/28"}},"content":"## Status\\n\\nSuperseded by [ADR 32](/adr/32)\\n\\n## Context\\n\\nThe current Head cluster is very fragile as has been observed on several occasions: A single hiccup in the connectivity between nodes while a head is open and nodes are exchanging messages can very easily lead to the Head being stuck and require an emergency closing, possibly even manually.\\n\\nWe want Hydra to be _Consistent_ in the presence of _Network Partitions_, under the _fail-recovery_ model assumption, eg. processes may fail by stopping and later recovering. Our system lies in the [CP](https://en.wikipedia.org/wiki/CAP_theorem) space of the landscape mapped by the CAP theorem.\\n\\nWe have identified 3 main sources of failures in the _fail-recovery_ model that can lead to a head being stuck:\\n\\n1. The network layer can drop messages from the moment a node `broadcast`s it, leading to some messages not being received at the other end\\n2. The sending node can crash in between the moment the state is changed (and persisted) and the moment a message is actually sent through the network (or even when it calls `broadcast`)\\n3. The receiving node can crash in between the moment the message has been received in the network layer, and it\'s processed (goes through the queue)\\n\\nWe agree that we\'ll want to address all those issues in order to provide a good user experience, as not addressing 2. and 3. can lead to hard to troubleshoot issues with heads. We have not experienced those issues yet as they would probably only crop up under heavy loads, or in the wild. But we also agree we want to tackle 1. first because it\'s where most of the risk lies. By providing a _Reliable Broadcast_ layer, we will significantly reduce the risks and can then later on address the other points.\\n\\nTherefore, the scope of this ADR is to address only point 1. above: Ensure broadcast messages are eventually received by all peers, given the sender does not stop before.\\n\\n### Discussion\\n\\n* We are currently using the [ouroboros-framework](https://github.com/input-output-hk/ouroboros-network) and [typed-protocols](https://github.com/input-output-hk/typed-protocols) network stack as a mere [transport](https://osi-model.com/transport-layer/) layer.\\n  * Being built on top of TCP, ouroboros multiplexer (Mux) provides the same reliability guarantees, plus the multiplexing capabilities of course\\n  * It also takes care of reconnecting to peers when a failure is detected which relieves us from doing so, but any reconnection implies a reset of each peer\'s state machine which means we need to make sure any change to the state of pending/received messages is handled by the applicative layer\\n  * Our [FireForget protocol](https://github.com/cardano-scaling/hydra/blob/8a8e0829964132bde8949e5249a1ab303af92fb8/hydra-node/src/Hydra/Network/Ouroboros/Type.hs#L31) ignores connections/disconnections\\n  * Ouroboros/typed-protocols provides enough machinery to implement a reliable broadcast protocol, for example by reusing existing `[KeepAlive](https://github.com/input-output-hk/ouroboros-network/tree/master/ouroboros-network-protocols/src/Ouroboros/Network/Protocol/KeepAlive)` protocol and building a more robust point-to-point protocol than what we have now\\n  * There is a minor limitation, namely that the subscription mechanism does not handle connections individually, but as a set of equivalent point-to-point full duplex connections whose size (valency) needs to be maintained at a certain threshold, which means that unless backed in the protocol itself, protocol state-machine and applications are not aware of the identity of the remote peer\\n* We have built our `Network` infrastructure over the concept of relatively independent layers, each implementing a similar interface with different kind of messages, to `broadcast` messages to all peers and be notified of incoming messages through a `callback`.\\n  * This pipes-like abstraction allows us to compose our network stack like:\\n\\n    ```\\n     withAuthentication (contramap Authentication tracer) signingKey otherParties $\\n      withHeartbeat nodeId connectionMessages $\\n        withOuroborosNetwork (contramap Network tracer) localhost peers\\n    ```\\n\\n  * This has the nice property that we can basically swap the lower layers should we need to, for example to use [UDP](https://github.com/cardano-scaling/hydra/blob/abailly-iohk/multi-node-udp/hydra-node/src/Hydra/Network/UDP.hs), or add other layers for example to address specific head instances in presence of [multiple heads](https://github.com/cardano-scaling/hydra/blob/abailly-iohk/multi-node-udp/hydra-node/src/Hydra/Network/MultiHead.hs#L26)\\n\\n## Decision\\n\\n* We implement our own message tracking and resending logic as a standalone `Network` layer\\n* That layer consumes and produces `Authenticated msg` messages as it relies on identifying the source of messages\\n* It uses a vector of monotonically increasing _sequence numbers_ associated with each party (including itself) to track what are the last messages from each party and to ensure FIFO delivery of messages\\n  * This _vector_ is used to identify peers which are lagging behind, resend the missing messages, or to drop messages which have already been received\\n  * The _Heartbeat_ mechanism is relied upon to ensure dissemination of state even when the node is quiescent\\n* We do not implement a _pull-based_ message communication mechanism as initially envisioned\\n* We do not persist messages either on the receiving or sending side at this time\\n\\n## Consequences\\n\\n* We keep our existing `Network` interface hence all messages will be resent to all peers\\n  * This could be later optimized either by providing a smarter interface with a `send :: Peer -> msg -> m ()` unicast function, or by adding a layer with filtering capabilities, or both\\n* We want to specify this protocol clearly in order to ease implementation in other languages, detailing the structure of messages and the semantics of retries and timeouts.\\n* We may consider relying on the vector clock in the future to ensure perfect ordering of messages on each peer and make impossible for legit transactions to be temporarily seen as invalid. This can happen in the current version and is handled through wait and _TTL_"},{"id":"28","metadata":{"permalink":"/head-protocol/adr/28","source":"@site/adr/2023-10-16_028_offline_adr.md","title":"28. Offline mode\\n","description":"Status","date":"2023-10-16T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":2.22,"hasTruncateMarker":false,"authors":[{"name":"Elaine Cardenas","title":"Software Engineer","url":"https://github.com/cardenaso11","imageURL":"https://github.com/cardenaso11.png","key":"cardenaso11","page":null}],"frontMatter":{"slug":"28","title":"28. Offline mode\\n","authors":["cardenaso11"],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"27. Network failures model\\n","permalink":"/head-protocol/adr/27"},"nextItem":{"title":"29. EventSource & EventSink abstractions\\n","permalink":"/head-protocol/adr/29"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nCurrently, the Hydra node requires a Layer 1 Cardano node running in order to operate; The L1 node is needed to submit and watch for L1 transactions. Generally speaking, the transactions watched are for learning the state of the Hydra node, as reflected by the L1 chain. The transactions submitted are to transition between states (e.g. after submitting a Commit tx to the L1, a node watches to see when all other nodes have also Committed.)\\n\\nThere are applications for the Hydra node where interaction with an L1 chain is unnecessary. Offline mode will be a key component of the Gummiworm protocol, a Layer 2 protocol being built by Sundae Labs, which enables actors other than Hydra head participants to validate transactions that occur in the head.\\n\\nThe Hydra node offline mode would remove the dependency on the L1 Cardano node, for applications like Gummiworm where it is unneeded. It would also remove the dependency on the L1 Cardano node for peer-to-peer Hydra node communication. This would be useful for other Layer 2s that build on top of Hydra instead of duplicating its efforts, and for anyone who wants to easily validate a set of Cardano transactions.\\n\\n## Decision\\n\\nHydra node will be executable in offline mode, as an alternative to the default online mode. When online, the Hydra node depends on querying a Cardano node for Era History information and Genesis parameters. When offline this is not necessary, because the Hydra node will not connect to any Layer 1 .\\n\\nThe initial state of the head will be specified in a flag, which makes any Commit redundant. The flag will specify a file for the starting Layer 2 UTXO. The Hydra node can be configured to write the current UTXO into a file, including the starting UTXO file.\\n\\nA node running in offline mode will not be able to switch between offline and online modes once started, as it is an unlikely use-case that would likely add more complexity.\\n\\nCommit endpoint will return 400 instead of building a transaction, in offline mode.\\n\\nSupport for peer Hydra nodes in offline mode is considered out of scope, as it doesn\'t seem immediately useful. A node running in offline mode will not be configurable with any peer nodes, nor will it make a network connection to any peer nodes.\\n\\n## Consequences\\n\\nThe Hydra node would be usable offline, for transaction validation, and other custom L2 applications. The lifecycle & state machine associated with a Hydra would remain unchanged in both online, and offline mode.\\n\\nThe Hydra node can be deployed and run without an accompanying Cardano node, simplifying deployment and testing."},{"id":"29","metadata":{"permalink":"/head-protocol/adr/29","source":"@site/adr/2023-11-07_029-event-source-sink.md","title":"29. EventSource & EventSink abstractions\\n","description":"Status","date":"2023-11-07T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":3.09,"hasTruncateMarker":false,"authors":[{"name":"Elaine Cardenas","title":"Software Engineer","url":"https://github.com/cardenaso11","imageURL":"https://github.com/cardenaso11.png","key":"cardenaso11","page":null},{"name":"Pi Lanningham","title":"Chief Technology Officer, Sundae Labs","url":"https://github.com/quantumplation","imageURL":"https://github.com/quantumplation.png","key":"quantumplation","page":null},{"name":"Sebastian Nagel","title":"Software Engineering Lead","url":"https://github.com/ch1bo","imageURL":"https://github.com/ch1bo.png","key":"ch1bo","page":null}],"frontMatter":{"slug":"29","title":"29. EventSource & EventSink abstractions\\n","authors":["cardenaso11","quantumplation","ch1bo"],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"28. Offline mode\\n","permalink":"/head-protocol/adr/28"},"nextItem":{"title":"30. Use CBOR in external representation of Cardano transactions\\n","permalink":"/head-protocol/adr/30"}},"content":"## Status\\nAccepted\\n\\n## Context\\n\\n* The Hydra node represents a significant engineering asset, providing layer 1 monitoring, peer to peer consensus, durable persistence, and an isomorphic Cardano ledger. Because of this, it is being eyed as a key building block not just in Hydra based applications, but other protocols as well.\\n\\n* Currently the `hydra-node` uses a very basic persistence mechanism for it\'s internal `HeadState`, that is saving `StateChanged` events to file on disk and reading them back to load and re-aggregate the `HeadState` upon startup.\\n  - Some production setups would benefit from storing these events to a service like Amazon Kinesis data stream instead of local files.\\n\\n* The `hydra-node` websocket-based API is the only available event stream right now and might not fit all purposes.\\n  - See also ADR [3](/adr/3) and [25](/adr/25)\\n  - Internally, this is realized as a single `Server` handle which can `sendOutput :: ServerOutput tx -> m ()`\\n  - These `ServerOutput`s closely relate to `StateChanged` events and `ClientEffect`s are yielded by the logic layer often together with the `StateChanged`. For example:\\n  ```hs\\n  onInitialChainAbortTx newChainState committed headId =\\n    StateChanged HeadAborted{chainState = newChainState}\\n      <> Effects [ClientEffect $ ServerOutput.HeadIsAborted{headId, utxo = fold committed}]\\n  ```\\n\\n* Users of `hydra-node` are interested to add alternative implementations for storing, loading and consuming events of the Hydra protocol.\\n\\n# Decision\\n\\n* We create two new interfaces in the `hydra-node` architecture:\\n\\n  - ```data EventSource e m = EventSource { getEvents :: m [e] }```\\n  - ```data EventSink e m = EventSink { putEvent :: e -> m () }```\\n\\n* We realize our current `PersistenceIncremental` used for persisting `StateChanged` events is both an `EventSource` and an `EventSink`\\n\\n* We drop the `persistence` from the main handle `HydraNode tx m`, add **one** `EventSource` and allow **many** `EventSinks`\\n\\n```hs\\ndata HydraNode tx m = HydraNode\\n  { -- ...\\n  , eventSource :: EventSource (StateEvent tx) m\\n  , eventSinks :: [EventSink (StateEvent tx) m]\\n  }\\n```\\n\\n* The `hydra-node` will load events and `hydrate` its `HeadState` using `getEvents` of the single `eventSource`.\\n\\n* The `stepHydraNode` main loop does call `putEvent` on all `eventSinks` in sequence. Any failure will make the `hydra-node` process terminate and require a restart.\\n\\n* When loading events from `eventSource` on `hydra-node` startup, it will also re-submit events via `putEvent` to all `eventSinks`.\\n\\n* The default `hydra-node` main loop does use the file-based `EventSource` and a single file-based `EventSink` (using the same file).\\n\\n* We realize that the `EventSource` and `EventSink` handles, as well as their aggregation in `HydraNode` are used as an API by forks of the `hydra-node` and try to minimize changes to it.\\n\\n## Consequences\\n\\n* The default operation of the `hyda-node` remains unchanged.\\n\\n* There are other things called `Event` and `EventQueue(putEvent)` right now in the `hydra-node`. This is getting confusing and when we implement this, we should also rename several things first (tidying).\\n\\n* Interface first: Implementations of `EventSink` should specify their format in a non-ambiguous and versioned way, especially when a corresponding `EventSource` exists.\\n\\n* The API `Server` can be modelled and refactored as an `EventSink`.\\n\\n* Projects forking the hydra node have dedicated extension points for producing and consuming events.\\n\\n* Sundae Labs can build a \\"Save transaction batches to S3\\" proof of concept `EventSink`.\\n* Sundae Labs can build a \\"Scrolls source\\" `EventSink`.\\n* Sundae Labs can build a \\"Amazon Kinesis\\" `EventSource` and `EventSink`.\\n\\n## Out of scope / future work\\n\\n* Available implementations for `EventSource` and `EventSink` could be\\n  - configured upon `hydra-node` startup using for example URIs: `--event-source file://state` or `--event-sink s3://some-bucket`\\n  - dynamically loaded as plugins without having to fork `hydra-node`.\\n\\n* The `Network` and `Chain` parts qualify as `EventSink`s as well or shall those be triggered by `Effect`s still?"},{"id":"30","metadata":{"permalink":"/head-protocol/adr/30","source":"@site/adr/2023-12-06_030-use-cbor-for-tx.md","title":"30. Use CBOR in external representation of Cardano transactions\\n","description":"Status","date":"2023-12-06T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":2.925,"hasTruncateMarker":false,"authors":[{"name":"Arnaud Bailly","title":"Lead Architect","url":"https://github.com/abailly-iohk","imageURL":"https://github.com/abailly-iohk.png","key":"abailly","page":null}],"frontMatter":{"slug":"30","title":"30. Use CBOR in external representation of Cardano transactions\\n","authors":["abailly"],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"29. EventSource & EventSink abstractions\\n","permalink":"/head-protocol/adr/29"},"nextItem":{"title":"31. Achieve constant memory in hydra-node\\n","permalink":"/head-protocol/adr/31"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* The [Hydra.Ledger.Cardano](https://github.com/cardano-scaling/hydra/blob/b2dc5a0da4988631bd2c1e94b66ba6217d5db595/hydra-node/src/Hydra/Ledger/Cardano.hs#L127) module provides `ToJSON/FromJSON` instances for `Tx` and [AlonzoTx](https://github.com/cardano-scaling/hydra/blob/b2dc5a0da4988631bd2c1e94b66ba6217d5db595/hydra-node/src/Hydra/Ledger/Cardano/Json.hs#L361)\\n  * We have specified this format as part of [Hydra API](https://github.com/cardano-scaling/hydra/blob/b2dc5a0da4988631bd2c1e94b66ba6217d5db595/hydra-node/json-schemas/api.yaml#L1473)\\n* These instances appear in a few places as part of Hydra API:\\n  * In the [ServerOutput](https://github.com/cardano-scaling/hydra/blob/b2dc5a0da4988631bd2c1e94b66ba6217d5db595/hydra-node/src/Hydra/API/ServerOutput.hs#L51) sent by the node to clients\\n  * In the [HydraNodeLog](https://github.com/cardano-scaling/hydra/blob/b2dc5a0da4988631bd2c1e94b66ba6217d5db595/hydra-node/src/Hydra/Node.hs#L122) as part of Hydra\'s logging output\\n  * In the [StateChanged](https://github.com/cardano-scaling/hydra/blob/b2dc5a0da4988631bd2c1e94b66ba6217d5db595/hydra-node/src/Hydra/HeadLogic/Outcome.hs#L46) events which are persisted and allow hydra-node to restart gracefully after stopping\\n* In other places the hydra-node produces, expects, or accepts a CBOR-encoded transaction:\\n  * In the [Network.Message](https://github.com/cardano-scaling/hydra/blob/b2dc5a0da4988631bd2c1e94b66ba6217d5db595/hydra-node/src/Hydra/Network/Message.hs#L20) exchanged between the nodes\\n  * In the [ClientInput](https://github.com/cardano-scaling/hydra/blob/b2dc5a0da4988631bd2c1e94b66ba6217d5db595/hydra-node/src/Hydra/API/ClientInput.hs#L9) from clients submitting `NewTx` commands\\n  * In the [HTTPServer](https://github.com/cardano-scaling/hydra/blob/b2dc5a0da4988631bd2c1e94b66ba6217d5db595/hydra-node/src/Hydra/API/HTTPServer.hs#L297) API\\n* Note that in the latter 2 cases, the hydra-node _accepts_ a hex-CBOR-encoded _JSON string_ to represent a transaction and this particular case is handled directly in the [FromJSON](https://github.com/cardano-scaling/hydra/blob/b2dc5a0da4988631bd2c1e94b66ba6217d5db595/hydra-node/src/Hydra/Ledger/Cardano/Json.hs#L388) instance for transactions where 3 different representations are even accepted:\\n  * JSON object detailing the transaction\\n  * A JSON string representing CBOR-encoding of a transaction\\n  * Or a `TextEnvelope` which wraps the CBOR transaction in a simple JSON object\\n* Using JSON-based representation of Cardano transactions is problematic because:\\n  * The representation we are providing is not _canonical_ nor widely used, and therefore require maintenance when the underlying cardano-ledger API changes\\n  * **More importantly** the JSON representation contains a `txId` field which is computed from the CBOR encoding of the transaction. When this encoding changes, the transaction id changes even though no other part of the transaction has changed. This implies that we could send and receive transactions with incorrect or inconsistent identifiers.\\n* This is true for any content-addressable piece of data, eg. any piece of data whose unique identifier is derived from the data itself, but not of say UTxO which is just data.\\n\\n## Decision\\n\\n* Drop support of \\"structured\\" JSON encoding of transactions in log messages, external APIs, and local storage of a node state\\n* Require JSON encoding for transactions that consists in:\\n  * A `cborHex` string field containing the base16 CBOR-encoded transaction\\n  * An optional `txId` string field containing the Cardano transaction id, i.e. the base16 encoded Blake2b256 hash of the transaction body bytes\\n  * When present, the `txId` MUST be consistent with the `cborHex`. This will be guaranteed for data produced by Hydra, but input data (eg. through a `NewTx` message) that does not respect this constraint will be rejected\\n\\n## Consequences\\n\\n* This is a breaking change and client applications must decode the full transaction CBOR before accessing any part of it\\n  - Hydra clients like `hydraw`, `hydra-auction`, `hydra-pay`, `hydra-poll` and hydra-chess` need to be updated\\n* By providing a `txId` field alongside the CBOR encoding, we still allow clients to observe the lifecycle of a transaction inside a Head as it gets validated and confirmed without requiring from them to be able to decode the CBOR body and compute the `txId` themselves\\n  * This is particularly important for monitoring which usually does not care about the details of transactions\\n* We should point users to existing tools for decoding transactions\' content in a human-readable format as this can be useful for troubleshooting:\\n  * `cardano-cli transaction view --tx-file <path to tx envelope file>` is one example\\n* We need to _version_ the data that\'s persisted and exchanged, e.g the Head state and network messages, in order to ensure nodes can either gracefully migrate stored data or detect explicitly versions inconsistency\\n* We should use the [cardanonical](https://github.com/CardanoSolutions/cardanonical) schemas should the need arise to represent transaction in JSON again"},{"id":"31","metadata":{"permalink":"/head-protocol/adr/31","source":"@site/adr/2024-01-27_031-constant-memory.md","title":"31. Achieve constant memory in hydra-node\\n","description":"Status","date":"2024-01-27T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.345,"hasTruncateMarker":false,"authors":[{"name":"Sasha Bogicevic","title":"Senior Software Engineer","url":"https://github.com/v0d1ch","imageURL":"https://github.com/v0d1ch.png","key":"v0d1ch","page":null}],"frontMatter":{"slug":"31","title":"31. Achieve constant memory in hydra-node\\n","authors":["v0d1ch"],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"30. Use CBOR in external representation of Cardano transactions\\n","permalink":"/head-protocol/adr/30"},"nextItem":{"title":"32. Network layer properties, implementation using etcd\\n","permalink":"/head-protocol/adr/32"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nWhen testing out hydra-node operation under heavy or increased load we are\\nnoticing that memory consumption is far from ideal. So far we didn\'t bother\\nthinking about the performance so much but time has come to try and reduce\\nmemory footprint of a running hydra-node.\\n\\nThere are some quick points to be scored here since our projections that are\\nused to serve in-memory data are using a common haskell list as a data\\nstructure. We should stream the data keeping the memory bounded as the first\\noptimisation.\\n\\nIt is also not necessary to output the whole history of messages by default and\\nonly do that if clients request to see the whole history. Internally our\\n`ServerOutput` type could be remapped to `StateChanged` since the two are\\nalmost identical. Any new information must be streamed to the clients\\nautomatically.\\n\\n## Decision\\n\\n- Re-map `ServerOutput` to `StateChanged` by adding any missing constructor to `StateChanged` (eg. `PeerConnected`).\\n- Output new client messages on `newState` changes instead of using `ClientEffect`.\\n- Use `StateChanged` in all projections we server from the API (re-use `eventId` as sequence number).\\n- Make hydra-node output history of messages only on demand (breaking change is to be communicated in the changelog).\\n- Use `conduit` library to achieve constant memory by streaming the data in our projections.\\n\\n## Consequences\\n\\nThis should lead to much better performance of hydra-node in terms of used\\nmemory for the running process. This should be also confirmed by running the\\nrelevant [benchmarks](https://github.com/cardano-scaling/hydra/issues/1724) and\\ndo a test (even manual or a script) to assert that the memory consumption is\\nactually reduced."},{"id":"32","metadata":{"permalink":"/head-protocol/adr/32","source":"@site/adr/2025-02-12_032-network-properties-etcd.md","title":"32. Network layer properties, implementation using etcd\\n","description":"Status","date":"2025-02-12T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":3.05,"hasTruncateMarker":false,"authors":[{"name":"Sebastian Nagel","title":"Software Engineering Lead","url":"https://github.com/ch1bo","imageURL":"https://github.com/ch1bo.png","key":"ch1bo","page":null}],"frontMatter":{"slug":"32","title":"32. Network layer properties, implementation using etcd\\n","authors":["ch1bo"],"tags":["Accepted"]},"unlisted":false,"prevItem":{"title":"31. Achieve constant memory in hydra-node\\n","permalink":"/head-protocol/adr/31"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n- The communication primitive of `broadcast` is introduced in [ADR 6](/adr/6). The original protocol design in the [paper](https://eprint.iacr.org/2020/299.pdf) and that ADR implicitly assume a **reliable broadcast**.\\n\\n- [ADR 27](/adr/27) further specifies that the `hydra-node` should be tolerant to the _fail-recovery_ failure model, and takes the decision to implement a _reliable broadcast_ by persisting outgoing messages and using a _vector clock_ and heartbeat mechanism, over a dumb transport layer.\\n  - The current transport layer in use is a simple _FireForget_ protocol over TCP connections implemented using `ouroboros-framework`.\\n  - [ADR 17](/adr/17) proposed to use UDP instead\\n  - Either this design or its implementation was discovered to be wrong, because this system did not survive fault injection tests with moderate package drops. \\n\\n- This [research paper](https://arxiv.org/pdf/1707.01873) explored various consensus protocols used in blockchain space and reminds us of the correspondence between consensus and broadcasts:\\n\\n  > the form of consensus relevant for blockchain is technically known as atomic broadcast\\n\\n  It also states that (back then):\\n\\n  > The most important and most prominent way to implement atomic broadcast (i.e., consensus) in distributed systems prone to t < n/2 node crashes is the family of protocols known today as Paxos and Viewstamped Replication (VSR).\\n\\n## Decision\\n\\n- We realize that the way the off-chain protocol is specified in the paper, the `broadcast` abstraction required from the `Network` interface is a so-called _uniform reliable broadcast_. Hence, any implementation of `Network` needs to satisfy the following **properties**:\\n\\n  1. **Validity**: If a correct process p broadcasts a message m, then p eventually delivers m.\\n  2. **No duplication**: No message is delivered more than once.\\n  3. **No creation**: If a process delivers a message m with sender s, then m was previously broadcast by process s.\\n  4. **Agreement**: If a message m is delivered by some correct process, then m is eventually delivered by every correct process.\\n\\n  See also Module 3.3 in [Introduction to Reliable and Secure Distributed Programming](https://www.distributedprogramming.net) by Cachin et al, or [Self-stabilizing Uniform Reliable Broadcast by Oskar Lundstr\xf6m](https://arxiv.org/abs/2001.03244)\\n\\n- Use [`etcd`](https://etcd.io/) as a proxy to achieve reliable broadcast via its [raft](https://raft.github.io/) consensus\\n  - Raft is an evolution of Paxos and similar to VSR\\n  - Over-satisfies requirements as it provides \\"Uniform total order\\" (satisfies [atomic broadcast](https://en.m.wikipedia.org/wiki/Atomic_broadcast) properties)\\n  - Each `hydra-node` runs a `etcd` instance to realize its `Network` interface\\n  - See the following architecture diagram which also contains some notes on `Network` interface properties:\\n\\n![](./2024-09-19-etcd-network-draft.jpg)\\n\\n- We supersede [ADR 17](/adr/17) and [ADR 27](/adr/27) decisions on how to implement `Network` with the current ADR.\\n  - Drop existing implementation of `Ouroboros` and `Reliability` components\\n  - Could be revisited, as in theory it would satisfy properties if implemented correctly?\\n  - Uniform reliable broadcast = only deliver when seen by everyone = not what we had implemented?\\n\\n## Consequences\\n\\n- Crash tolerance of up to `n/2` failing nodes\\n\\n- Using `etcd` as-is adds a run-time dependency onto that binary.\\n  - Docker image users should not see any different UX\\n  - We can ship the binary through `hydra-node`.\\n\\n- Introspectability network as the `etcd` cluster is queryable could improve debugging experience\\n\\n- Persisted state for networking changes as there will be no `acks`, but the `etcd` Write Ahead Log (WAL) and a last seen revision.\\n\\n- Can keep same user experience on configuration\\n  - Full, static topology with listing everyone as `--peer`\\n  - Simpler configuration via [peer discovery](https://etcd.io/docs/v3.5/op-guide/clustering/#discovery) possible\\n\\n- `PeerConnected` semantics needs to change to an overall `HydraNetworkConnected`\\n  - We can only submit / receive messages when connected to the majority cluster\\n\\n- `etcd` has a few features out-of-the-box we could lean into, e.g.\\n  - use TLS to secure peer connections\\n  - separate advertised and binding addresses"}]}}')}}]);