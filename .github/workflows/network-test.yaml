name: "Network fault tolerance"

on:
  pull_request:
  workflow_dispatch:
    inputs:
      debug_enabled:
        type: boolean
        description: 'Run the build with tmate debugging enabled (https://github.com/marketplace/actions/debugging-with-tmate)'
        required: false
        default: false
      wait_peer_disconnected:
        type: boolean
        description: 'Check other peers see the target peer is disconnected before running benchmark.'
        required: false
        default: false
      target_peer:
        description: 'Select the peer to target with netem package loss'
        required: true
        type: choice
        options:
          - alice
          - bob
          - carol
        default: alice

jobs:
  network-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        # Note: At present we can only run for 3 peers; to configure this for
        # more we need to make the docker-compose spin-up dynamic across
        # however many we would like to configure here.
        peers:          [3]
        scaling_factor: [10, 50]
        netem_loss:     [0, 1, 2, 3, 4, 5, 10, 20]
    name: "Peers: ${{ matrix.peers }}, scaling: ${{ matrix.scaling_factor }}, loss: ${{ matrix.netem_loss }}"
    steps:
    - uses: actions/checkout@v4
      with:
        submodules: true

    - name: ‚ùÑ Prepare nix
      uses: cachix/install-nix-action@V27
      with:
        extra_nix_config: |
          accept-flake-config = true
          log-lines = 1000

    - name: ‚ùÑ Cachix cache of nix derivations
      uses: cachix/cachix-action@v15
      with:
        name: cardano-scaling
        authToken: '${{ secrets.CACHIX_CARDANO_SCALING_AUTH_TOKEN }}'

    - name: Build docker images for netem specifically
      run: |
        nix build .#docker-hydra-node-for-netem
        ./result | docker load

    - name: Setup containers for network testing
      run: |
        cd demo
        ./prepare-devnet.sh
        docker compose up -d cardano-node
        sleep 5
        # :tear: socket permissions.
        sudo chown runner:docker devnet/node.socket
        ./export-tx-id-and-pparams.sh
        # Specify two docker compose yamls; the second one overrides the
        # images to use the netem ones specifically
        docker compose -f docker-compose.yaml -f docker-compose-netem.yaml up -d hydra-node-{1,2,3}
        sleep 3
        docker ps

    - name: Build required nix and docker derivations
      run: |
        nix build .#legacyPackages.x86_64-linux.hydra-cluster.components.benchmarks.bench-e2e
        nix build github:noonio/pumba/noon/add-flake

    # Use tmate to get a shell onto the runner to do some temporary hacking
    #
    # <https://github.com/mxschmitt/action-tmate>
    #
    - name: Setup tmate session
      uses: mxschmitt/action-tmate@v3
      if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.debug_enabled }}
      with:
        limit-access-to-actor: true

    - name: Run pumba and the benchmarks
      # Note: We're going to allow everything to fail. In the job on GitHub,
      # we will be able to see which ones _did_, in fact, fail. Originally,
      # we were keeping track of our expectations with 'include' and
      # 'exclude' directives here, but I think it's best to leave those out,
      # as some of the tests (say 5%) fail, and overall the conditions of
      # failure depend on the scaling factor, the peers, etc, and it becomes
      # too complicated to track here.
      continue-on-error: true
      run: |
        # Extract inputs with defaults for non-workflow_dispatch events
        peers="${{ matrix.peers }}"
        percent="${{ matrix.netem_loss }}"
        scaling_factor="${{ matrix.scaling_factor }}"
        target_peer="${{ github.event.inputs.target_peer || 'alice' }}"

        peers_info_json=$(.github/workflows/network/peers_info_json.sh)

        .github/workflows/network/run_pumba.sh $target_peer $percent $peers_info_json

        wait_peer_disconnected="${{ github.event.inputs.wait_peer_disconnected || false }}"

        if [[ "$wait_peer_disconnected" == "true" ]]; then
          .github/workflows/network/watch_logs.sh $target_peer $peers_info_json
        fi

        client_args=""
        for i in $(seq 1 $peers); do
          port=$((4000 + $i))
          client_args+=" --hydra-client=localhost:$port"
        done

        # Run benchmark on demo
        mkdir benchmarks
        touch benchmarks/test.log

        nix run .#legacyPackages.x86_64-linux.hydra-cluster.components.benchmarks.bench-e2e -- \
          demo \
          --output-directory=benchmarks \
          --scaling-factor="$scaling_factor" \
          --timeout=1000s \
          --testnet-magic 42 \
          --node-socket=demo/devnet/node.socket \
          $client_args

    - name: Acquire logs
      if: always()
      run: |
        cd demo
        docker compose logs > docker-logs

    - name: üíæ Upload logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: "docker-logs-netem-loss=${{ matrix.netem_loss }},scaling_factor=${{ matrix.scaling_factor }},peers=${{ matrix.peers }}"
        path: demo/docker-logs
        if-no-files-found: ignore

    - name: üíæ Upload build & test artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: "benchmarks-netem-loss=${{ matrix.netem_loss }},scaling_factor=${{ matrix.scaling_factor }},peers=${{ matrix.peers }}"
        path: benchmarks
        if-no-files-found: ignore
